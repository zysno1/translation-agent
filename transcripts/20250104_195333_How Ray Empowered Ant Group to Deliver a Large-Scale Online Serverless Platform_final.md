---
video_id: _yu0Rtuetuc
video_url: https://www.youtube.com/watch?v=_yu0Rtuetuc
video_title: How Ray Empowered Ant Group to Deliver a Large-Scale Online Serverless Platform
created_at: 2025-01-04 19:55:10
---

# How Ray Empowered Ant Group to Deliver a Large-Scale Online Serverless Platform

[00:06 - 00:08] 大家好。
[00:08 - 00:12] 我们是来自艺术小组的顾阳松和ZLI。
[00:12 - 00:17] 今天的主题是由我们团队的负责人魏才带领的。
[00:17 - 00:21] 但他今天不能到场，所以我们将会作为演讲者。
[00:21 - 00:30] 这是我们第一次来到这里，我们非常高兴能在这里分享我们的工作。
[00:30 - 00:40] 今天的话题是关于我们如何赋能艺术小组交付一个大规模在线服务平台。
[00:40 - 00:40] 让我们开始。
[00:41 - 00:46] 首先，我想介绍一下我的公司和我的团队。
[00:46 - 01:00] 总结起来，我们有五个方向：数字支付、数字连接、数字金融、数字技术和全球化。
[01:00 - 01:16] 我们最受欢迎的应用程序是阿里，它在中国引领了互联网、支付和金融领域。我的团队是Anthree团队。
[01:16 - 01:23] 在下一页中，我将向您展示我们团队的历史和信息。
[01:23 - 01:29] 但在那之前，我想先分享一些高层信息。
[01:30 - 01:39] 首先，我们是第二大贡献开源软件Ray的团队。
[01:39 - 01:56] 我们与AnyScale和ResLab合作多年，并且在开源部分的贡献超过26%。
[01:56 - 02:13] 此外，在开发Ray之外，我们在生产环境中也有大量的Ray应用，我们每天有超过100万个CPU调用。
[02:14 - 02:25] 而在中国，我们也拥有一个由我们团队创建和运营的活跃社区。
[02:25 - 02:32] 过去五年里，我们每年都会举办ReFrward Meetup。
[02:32 - 02:52] 第五届ReFrward已经在上个月结束，在这次会议上，AnyScale、Cross AI、A'T和Bad Dance都分享了他们的工作。
[02:52 - 03:01] 因此，我们希望Ray在中国也能像在美国一样受欢迎。
[03:02 - 03:07] 让我们进入关于Rain在Art中的历史部分。
[03:07 - 03:16] 我们的团队成立于2017年，这一年Ray与现在有所不同。
[03:16 - 03:31] 我们认为Ray是一个通用的分布式系统，这意味着我们有很多非AI应用程序和框架。

[03:31 - 03:45] 众所周知，Reopen Source 专注于 Python 和 AI，这意味着首先关注 Python，其次是 AI，但我们与众不同。
[03:45 - 03:55] 因此，你可以看到我们已经为 Reopen Source 贡献了 Python、Java 和 C++ API。
[03:55 - 04:05] 在 2018 年，我们的第一个用户层引擎部署到了生产环境中。
[04:05 - 04:11] 该引擎名为 GFlow，是一个流式图引擎。
[04:11 - 04:17] 它被用于支付宝支付的风险控制。
[04:17 - 04:29] 在 2019 年，另一个融合引擎在生产环境中部署。
[04:29 - 04:31] 该引擎是基于学习的。
[04:31 - 04:40] 我们实现了三种计算类型，包括流式计算、机器学习和在线服务。
[04:40 - 04:51] 所以你可以知道这次在线服务也在 Art 中部署，它是主题。
[04:51 - 05:08] 在 2020 年，鉴于业务多样性，我们构建了一个多架构的 Ruh，这意味着你可以在一个大的 Rec 集群中运行多个 Rjobs。
[05:08 - 05:16] 在这个任务中，你可以支持不同的计算范式。
[05:16 - 05:22] 在 2021 年，系统变得更加稳定。
[05:22 - 05:35] 我们与生态系统公司如阿里达摩院、中国网和万商银行进行了更多的合作。
[05:36 - 05:45] 在 2022 年，我们探索了隐私计算这一新场景。
[05:45 - 05:53] 我们认为，隐私计算是一个很好的应用场景。
[05:53 - 06:07] 因为在隐私计算中，我们需要灵活的框架来支持常见的功能数据和 AI，这有许多优势。
[06:08 - 06:28] 好的，在今年即 2023 年，我们旨在构建一个通用的 AI 服务框架，在这个框架中，我们希望统一传统的 AI 大型语言模型和搜索引擎。
[06:28 - 06:32] 这是今天的主题。
[06:32 - 06:34] 回到在线服务。
[06:34 - 06:48] 从历史时间线可以看出，在 2019 年，这项在线服务首先在 Ant 中部署。
[06:48 - 06:54] 它被集成到在线学习引擎中。
[06:54 - 06:56] 依赖于此，
[06:56 - 07:05] 我们构建了基本的预留能力，并将其集成到 Art 集团的基础架构中。

[07:05 - 07:13] 您知道每家公司都有其客户基础设施，因此我们需要采用它。
[07:13 - 07:22] 而在2021年，我们还有另一个场景，即在线资源分配。
[07:22 - 07:34] 您可以想象，如果资源用于支付和金融，会面临哪些挑战？
[07:34 - 07:44] 我们认为这些挑战在于我们需要一个更灵活、高性能且可扩展、稳定的框架。
[07:44 - 07:59] 幸运的是，我们在2020年基于R&E实现了这一点，并在2022年支持了大规模在线服务。
[07:59 - 08:12] 在此期间，我们的服务模型调用量达到了240,000次，事件驱动的服务平台达到了137万PC TPS。
[08:12 - 08:16] 好的，这就是我们所有的私有工作。
[08:16 - 08:24] 下面我将介绍我们今年的最新成果。
[08:24 - 08:25] 欢迎。
[08:25 - 08:26] 好的。
[08:26 - 08:29] 谢谢，Guam，大家好。
[08:29 - 08:40] 我叫李东，非常高兴在这里与大家分享我们在2023年的最新成果。
[08:40 - 08:46] 在End Group，我们已经建立了最大的推理平台。
[08:46 - 08:52] 我们的推理集群共有50万台CPU和4000台GPU。
[08:52 - 09:00] 我相信你们昨天已经在Doctor Stoker的Ken O演讲中看到了这些数字。
[09:00 - 09:07] 为了提供这些硬件，我们总共使用了超过27000个工作站。
[09:07 - 09:14] 作为一个推理平台，我们的平台上部署了大量的活跃模型。
[09:14 - 09:23] 每周我们有超过3000个新的模型部署，每周有超过10万个模型更新。
[09:23 - 09:28] 我们的推理集群具有高度的自动扩展能力。
[09:28 - 09:41] 因此，得益于我们的产品线和独立自动扩展器，我们的推理集群现在每周可以主动进行超过3000次的自动扩展。
[09:41 - 09:48] 通过这种方式，我们提高了平均CPU利用率超过20%。
[09:51 - 09:58] 所以下面我将讨论一些生产中的新场景以及我们实现的一些新功能。
[09:59 - 10:07] 在详细介绍之前，我想首先展示一下我们Reay服务架构的概述。
[10:07 - 10:12] 它与开源版本没有太大区别。
[10:12 - 10:17] 在这个架构中，我们有一个服务守护进程。

[10:17 - 10:29] 它接收来自用户客户端的所有在线推理任务提交，并且需要将这些在线任务分配到我们的在线集群中。
[10:29 - 10:40] 但是，对于每个任务，服务守护进程需要在一个特定的服务集群中创建一个相应的应用程序主控。
[10:40 - 10:47] 这个应用程序主控将在集群内创建多个代理和部署角色。
[10:48 - 10:57] 当这些代理准备好后，它们会向独立的服务发现组件注册自己。
[10:57 - 11:12] 通过订阅该组件，我们的用户应用可以获知每个代理的位置，并仔细选择最合适的代理来发送其推理请求。
[11:13 - 11:27] 而在每个代理中，您必须将传入的推理请求分配给本地部署角色，在那里完成模型服务工作。
[11:29 - 11:32] 好的，现在是新的场景。
[11:32 - 11:36] 第一种是在GPU上进行模型服务工作。
[11:36 - 11:41] 为了实现这一点，我们选择了使用Triton。
[11:41 - 11:51] 对于那些不熟悉Triton的人来说，它是一个视频流单节点模型推理引擎。
[11:51 - 12:01] 它支持多种推理后端，在我们的预留系统中，Triton服务器可以非常容易地分布。
[12:01 - 12:09] 我们所需要做的就是让部署角色成为Triton服务器。
[12:09 - 12:19] 因此，每当应用程序主控创建一个新的部署角色时，它将立即启动内部的Triton服务器。
[12:19 - 12:27] 在我们的运行时环境的帮助下，这个运行时环境特性非常有用。
[12:27 - 12:38] 它是由开源召回提供的，并且在处理数据依赖包或库依赖程序时帮助很大。
[12:38 - 12:46] 我相信我们的召回团队为开源贡献了近一半的实现。
[12:46 - 12:47] 是的。
[12:47 - 13:06] 因此，当这些跟踪服务器准备就绪时，它们可以选择向此服务发现组件注册自己，随后的推理请求可以直接连接到这些Triton服务器。

[13:06 - 13:21] 有一点需要提到的是，由于我们的服务集群具有高度的自动扩展能力，因此当您在我们的平台上运行 trton 服务器时，它们也会变得自动扩展。
[13:23 - 13:29] 好的，下一个场景是服务区域 m 应用程序。
[13:29 - 13:38] 这个背景是在我们团队中，我们有一个名为 GPT t 现金存储系统（GPT t cash storage）。
[13:38 - 13:48] 在这个系统中，我们会尝试将历史的 LM 响应存储在我们的向量或现金存储中。
[13:48 - 13:57] 因此，每当有新的推理请求进来时，我们首先进行相似性比较。
[13:57 - 14:11] 如果缓存命中，则我们直接返回预先存储的响应给用户；如果缓存未命中，则推理请求仍需通过模型服务管道。
[14:12 - 14:22] 在我们的预留平台中，这个对话系统（GPT t 现金系统）可以很容易地集成。
[14:22 - 14:33] 我们只需在部署演员（deployment actor）内部运行这个 GPT 现金系统，并利用演员运行时功能。
[14:33 - 14:47] 当然，我们需要在集群中有一个入口演员（ingress actor），它会帮助我们将每个进入的推理请求转发到 GBT 现金演员。
[14:47 - 14:50] 然后我们仍然做同样的事情。
[14:50 - 14:53] 如果缓存命中，则我们快速响应。
[14:53 - 15:04] 如果缓存未命中，则我们只需将请求转发到另一个在部署演员中运行的 Triton 服务器。
[15:06 - 15:21] 在这张图中可以看到的一个重要点是，G P GPD 现金演员（G P GPD cash actors）运行在 CPU 节点上，而 Triton 服务器则运行在 GPU 节点上。
[15:21 - 15:37] 由于资源异构调度的优势，我们现在可以更明智地分配这些不同类型的演员，从而优化整体资源利用率。
[15:39 - 15:42] 好的，接下来是一些新功能。
[15:42 - 15:46] 第一个功能是构建异步经纪人（asynchronous broker）。
[15:46 - 15:58] 我们这样做是因为在大多数模型服务场景中，我们发现推理请求的执行时间各不相同。
[15:58 - 16:07] 因此，对于这些长请求，人们总是需要支付大量的同步等待开销。

[16:07 - 16:14] 我们在这里所做的工作是，在服务集群中部署了一个异步代理。
[16:14 - 16:20] 当然，这个异步代理也是运行在一个部署演员（deployment actor）中。
[16:20 - 16:26] 这个异步代理可以接收每个传入的推理请求队列。
[16:26 - 16:38] 对于这些长请求，当结果准备好时，异步代理可以帮助我们异步地将这些结果返回给用户。
[16:40 - 17:03] 我认为这个异步代理的一大好处在于，由于它位于集群内部，其他部署演员可以根据自身忙碌或空闲状态从这个代理中自适应地拉取推理请求。
[17:03 - 17:18] 通过这种方式，在每个运行着 Triton 服务器的部署演员中，我们可以看到更少的队首延迟（head-of-line delay）。
[17:19 - 17:35] 因此，在我们的评估中，与基于错误的轮询推送分配方法相比，我们的基于代理的方法可以提供两倍的吞吐量。
[17:38 - 17:42] 下一个功能是 C++ 部署。
[17:42 - 17:50] 这个功能已经被广泛应用于我们的推荐和广告业务服务中。
[17:50 - 17:55] 这些服务对延迟敏感且需要高吞吐量。
[17:55 - 18:04] 因此，由于这些性能需求，我们的部署演员也必须具有高性能。
[18:04 - 18:15] 所以我们所做的是使用基于开源框架 C++ 工作者（C++ workers）的 C++ 部署演员。
[18:15 - 18:22] 另外，这些 C++ 工作者主要由我们的团队贡献。
[18:22 - 18:25] 所以感谢 Gyang 在这方面的工作。
[18:25 - 18:36] 好的，有了这些 C++ 部署演员之后，我们实现了一项重要的功能——C++ 直接入口（C++ direct ingress）。
[18:36 - 18:40] 它是一个高性能的 RPC 服务。
[18:40 - 18:54] 通过这一功能，我们的推理请求可以直接连接到我们的 C++ 部署演员，绕过所有上述提到的代理。
[18:56 - 19:01] 另一项重要的功能是原生 Triton 推理调用。
[19:01 - 19:20] 由于我们现在拥有 C++ 部署演员和 Triton 服务器（可以被视为一个 C++ 库），因此可以更紧密且高效地集成，而没有任何跨语言开销。

[19:20 - 19:40] 当我们制作 C++ 部署演员时，与推荐系统和广告时间线中的其他 C++ 组件协同工作，并且实际上在进行一个更全面的分布式系统。
[19:43 - 19:48] 好的，接下来我将谈论一些未来的计划。
[19:48 - 19:54] 我们首先要做的是共享部署。
[19:54 - 20:11] 这个举措的动机在于我们的推荐和服务搜索中，使用 CVR 或 CTR 模型时，可以看到大量具有大型特征的数据项。
[20:11 - 20:19] 而这些特征数据的大小太大，无法适应任何单一的工作节点。
[20:19 - 20:30] 因此，我们必须尝试将这些大型特征数据分布在多个工作节点上。
[20:30 - 20:56] 当然，我们将创建代理部署演员，利用这个代理来帮助我们实现数据迁移路由策略，并确保每个传入的推理请求都能被转发到具有本地可用数据依赖性的特定节点。
[20:59 - 20:59] 好的。
[20:59 - 21:04] 所以最后一点是关于整体规划。
[21:04 - 21:13] 我们希望交付高性能通用 AI 框架来实现这一目标。
[21:13 - 21:33] 首先，我们将继续构建和完善基于开源储备的推荐平台。该平台已被证明是高度分布式的、多语言支持和可扩展的。
[21:33 - 21:40] 我们相信这可以成为许多模型服务场景的良好基础。
[21:42 - 21:52] 我们肯定会使用直接入口并用其构建高性能 RPC 服务。
[21:52 - 22:04] 我们会广泛使用 C++ 部署演员，因为它们能提供高性能计算能力。
[22:05 - 22:16] 我们将开始致力于共享部署，这将为我们提供高性能的本地数据访问和数据检索。
[22:16 - 22:26] 我们认为，当未来处理大规模模型服务问题时，这一特性将变得非常关键。
[22:28 - 22:32] 所以，这就是我们今天的所有内容。
[22:32 - 22:39] 如我在开始时所说，这项工作主要由我们的 BUD 团队的 Ten G Wei 完成。

[22:39 - 22:43] 我们会尽力在这里回答问题。
[22:43 - 22:53] 如果我们无法回答，请大家发送邮件到这个地址，我相信他能给出最详细的解答。
[22:53 - 22:55] 谢谢。
[23:02 - 23:12] 关于您提到的直接接入和C++的工作，其中有多少已经集成到开源项目中？
[23:12 - 23:19] 它已经是开源的了，但实际上在开源社区中并不太受欢迎。
[23:19 - 23:40] 但是我们在生产环境中大量使用它，特别是在推荐和广告系统中，因为我们希望使推荐管道中的所有组件都用C++实现，从而使得整个管道更加完整。
[23:42 - 23:55] 一个后续问题是，在您提到的推荐管道中，您实际使用Ray做什么？
[23:55 - 23:58] 因为使用Triton进行推理，对吗？
[23:58 - 24:04] 您还使用了这个直接接入，但Ray在这个场景中扮演什么角色？
[24:04 - 24:07] Ray是如何帮助您的？
[24:07 - 24:19] 是的，我们确实使用Ray异构环境来帮助我们整合Triton依赖项在我们的部署Actor中。
[24:19 - 24:32] 我们使用Ray异构调度来帮助我们调度这些Actor，无论是CPU依赖还是GPU依赖的Actor。
[24:32 - 24:40] 这些Actor可以很好地调度，并帮助提高资源利用率。
[24:46 - 24:48] 谢谢您的分享。
[24:48 - 24:50] 快速提问。
[24:50 - 24:58] 您提到每周有超过3000个模型部署。
[24:58 - 25:07] 我的问题是，对于一种类型的模型，平均或通常的部署频率是多少？
[25:07 - 25:14] 比如说，对于大型语言模型，你们多久更新和部署一次？
[25:14 - 25:31] 是的，这个问题您应该给Ten G Wei发邮件，因为这涉及服务团队的一些细节。
[25:37 - 25:42] 这是一个与Ray选择相关的共享部署问题。
[25:42 - 25:47] 是的，这是一个与Ray选择相关的共享部署问题。

[25:47 - 26:05] 是的，我们仍然在使用 Ray。我们需要关闭这个特性数据跨多个 Walker 节点，但 Walker 节点仍然基于 Ray，并且所有参与者都被处理为反应器。
[26:13 - 26:19] 所有这些都运行在类似于虚拟机（VM）上，而不是 Kubernetes 或其他任何中间件。
[26:19 - 26:20] 只是虚拟机（VM）。
[26:20 - 26:23] 我们所有的集群是否只是运行在虚拟机（VM）上？
[26:23 - 26:25] 还是在 Kubernetes 上运行？
[26:25 - 26:35] 不，我们肯定是在 Kubernetes 的云原生环境中运行我们的集群。
[26:43 - 26:48] 哦，如果没有更多问题，那么非常感谢大家。
[26:48 - 26:48] 好的。
[26:48 - 26:50] 谢谢大家。