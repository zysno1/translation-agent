---
video_id: _yu0Rtuetuc
video_url: https://www.youtube.com/watch?v=_yu0Rtuetuc
video_title: How Ray Empowered Ant Group to Deliver a Large-Scale Online Serverless Platform
created_at: 2025-01-04 10:47:16
---

# How Ray Empowered Ant Group to Deliver a Large-Scale Online Serverless Platform

[00:06 - 00:08] 大家好。
[00:08 - 00:12] 我们是来自艺术小组的古阳松和ZLI。
[00:12 - 00:17] 今天的话题是由我们的伙伴团队的韦财带领的。
[00:17 - 00:21] 但他今天不能来这里，所以我们将会作为演讲者。
[00:21 - 00:30] 这是我们第一次来到这里，我们非常高兴能够在这里分享我们的作品。
[00:30 - 00:40] 今天的话题是关于如何赋能艺术小组提供大规模在线服务平台。
[00:40 - 00:40] 让我们开始吧。
[00:41 - 00:46] 首先，我想介绍一下我的公司和我的团队。
[00:46 - 01:00] 总结一下，我们小组有五个方向：数字支付、数字连接、数字金融、数字技术和全球化。
[01:00 - 01:16] 而我们最受欢迎的应用程序是蚂蚁集团的支付宝，它在中国引领着互联网、支付和金融领域，而我的团队是蚂蚁集团的第三个团队。
[01:16 - 01:23] 在下一页，我会向你们展示很多关于我们团队的历史信息。
[01:23 - 01:29] 但在这里我想先分享一些高层次的信息。
[01:30 - 01:39] 首先，我们是为Ray开源软件贡献第二大的团队。
[01:39 - 01:56] 我们与任何规模和RESLab合作多年，并且在开源部分中，我们贡献了超过26%的记录。
[01:56 - 02:13] 其次，除了开发Ray之外，我们在生产中还有大量大规模应用，我们现在有超过1百万的CPU调用。
[02:14 - 02:25] 此外，在中国，我们也拥有一个丰富的中国社区，这个社区由我的团队创建和运营。
[02:25 - 02:32] 而且在过去五年中，我们每年都会举办一次Ray Forward Meetup。
[02:32 - 02:52] 第五届Ray Forward Meetup已经在去年七月结束，而在此次会议上，AnyScale、Cross AI、A&T和Bad Dance都分享了他们的作品。
[02:52 - 03:01] 所以我们希望Ray在中国也能像在美国一样受欢迎。
[03:02 - 03:07] 让我们进入Rain在艺术中的历史部分。
[03:07 - 03:16] 我们的团队成立于2017年，这一年Ray与今天有所不同。
[03:16 - 03:31] 我们认为Ray是一个通用的分布式系统，这意味着我们有很多非AI应用和框架。

[03:31 - 03:45] 你知道，重启源项目专注于Python和人工智能，这意味着首先关注Python，但我们与众不同。
[03:45 - 03:55] 所以你可以看到，我们已经为重启项目贡献了Pi、Java和C++的API。
[03:55 - 04:05] 在2018年，我们的第一个用户播放器引擎被部署到生产环境中。
[04:05 - 04:11] 这个引擎的名字叫GFlow，它是一个流图引擎。
[04:11 - 04:17] 它用于支付宝支付的风险控制。
[04:17 - 04:29] 在2019年，另一个融合引擎被部署在生产环境中。
[04:29 - 04:31] 这个引擎涉及学习。
[04:31 - 04:40] 我们实现了三种计算类型，包括流式处理、机器学习和在线服务。
[04:40 - 04:51] 因此，这次在线服务也在艺术领域中进行了部署，并成为了一个话题。
[04:51 - 05:08] 在2020年，考虑到业务的多样性，我们实现了多架构Ruh，这意味着你可以在一个大的REC集群中运行许多R作业。
[05:08 - 05:16] 在这个作业中，你可以支持不同的计算范式。
[05:16 - 05:22] 在2021年，该系统更加稳定。
[05:22 - 05:35] 我们与生态系统公司如阿里达摩院、中国网络和万商银行等有更多的合作。
[05:36 - 05:45] 在2022年，我们探索了隐私计算这一新场景。
[05:45 - 05:53] 我们认为，在隐私计算中，这是一个很好的场景。
[05:53 - 06:07] 因为在隐私计算中，我们需要灵活的框架来支持常见的数据功能和人工智能，这对司法有很多优势。
[06:08 - 06:28] 好的，在2023年，我们旨在构建一个通用的人工智能服务框架，在这个框架下，我们希望统一传统的人工智能大语言模型和服务引擎。
[06:28 - 06:32] 这就是今天的主题。
[06:32 - 06:34] 回到在线服务。
[06:34 - 06:48] 从历史时间线可以看出，在2019年，这种在线服务首次在蚂蚁集团部署。
[06:48 - 06:54] 并且它整合到了在线学习引擎中。
[06:54 - 06:56] 依赖于此。
[06:56 - 07:05] 我们建立了基本的保留能力，并将其整合到蚂蚁集团的基础架构中。

[07:05 - 07:13] 你知道每家公司都有自己的客户基础设施，所以我们需要采纳它。
[07:13 - 07:22] 在2021年，我们还有另一个场景，即在线资源分配。
[07:22 - 07:34] 你可以想象，如果资源用于支付和金融领域，会面临哪些挑战？
[07:34 - 07:44] 我们认为，挑战在于我们需要一个更加灵活、高性能且可扩展、稳定的框架。
[07:44 - 07:59] 幸运的是，我们在2020年基于R&E实现了这一点，并在2022年支持了大规模的在线监控平台。
[07:59 - 08:12] 在那时，我们的服务模型达到了每周24万次调用，事件驱动的监控平台达到了每秒137万次TPS。
[08:12 - 08:16] 好的，这就是我们所有的私有工作。
[08:16 - 08:24] 下面Chwill将介绍我们今年的最新成就。
[08:24 - 08:25] 欢迎。
[08:25 - 08:26] 好的。
[08:26 - 08:29] 谢谢，Guan，大家好。
[08:29 - 08:40] 我叫李同，非常高兴在这里与大家分享我们在2023年的最新成就。
[08:40 - 08:46] 在End Group，我们已经建立了最大的推理平台。
[08:46 - 08:52] 我们的推理集群总共有50万CPU核心和4000个GPU核心。
[08:52 - 09:00] 我相信你们昨天在Dr. Stoker的肯演讲中已经看到了这些数字。
[09:00 - 09:07] 为了提供这些硬件，我们总共使用了超过27000个工作站。
[09:07 - 09:14] 作为推理平台，我们的平台上部署了大量的活跃模型。
[09:14 - 09:23] 每周我们有超过3000个新模型部署，每周有超过10万个模型更新。
[09:23 - 09:28] 我们的推理集群具有高度自动扩展能力。
[09:28 - 09:41] 因此，得益于我们的产品集成和独立自动扩展器，我们的推理集群现在每周可以主动进行超过3000次自动扩展。
[09:41 - 09:48] 通过这种方式，我们提高了平均CPU利用率超过20%。
[09:51 - 09:58] 所以下面我将讨论我们在生产中的新场景以及一些新功能。
[09:59 - 10:07] 在详细介绍之前，我想首先展示一下我们Reay服务架构的概览。
[10:07 - 10:12] 这与开源版本并没有太大不同。
[10:12 - 10:17] 在这个架构中我们有服务守护进程。

[10:17 - 10:29] 它接收来自用户客户端的所有推理作业提交，并且必须将这些推理作业分配到我们的推理集群中。
[10:29 - 10:40] 但对于每个作业，推理守护程序需要在某个特定的推理集群中创建一个相应的应用程序主控。
[10:40 - 10:47] 这个应用程序主控将在集群内创建多个代理和部署角色。
[10:48 - 10:57] 当这些代理准备好后，它们会向独立的服务发现组件注册自己。
[10:57 - 11:12] 通过订阅这个组件，我们的用户应用可以了解每个代理的位置，并仔细选择最合适的代理来发送推理请求。
[11:13 - 11:27] 而在每个代理中，必须为传入的推理请求分配使用本地部署角色，在那里完成模型推理工作。
[11:29 - 11:32] 好的，现在讨论新的场景。
[11:32 - 11:36] 第一种是在GPU上进行模型推理。
[11:36 - 11:41] 为了实现这一点，我们选择了使用视频Triton。
[11:41 - 11:51] 对于不熟悉Triton的人来说，它是一种视频单节点模型推理系统。
[11:51 - 12:01] 它支持多种推理后端，在我们的保留系统中，Triton服务器可以非常容易地被分布。
[12:01 - 12:09] 我们需要做的就是让部署角色成为Triton启动器。
[12:09 - 12:19] 因此，每当应用程序主控创建一个新的部署角色时，它会立即启动Triton服务器。
[12:19 - 12:27] 在我们演员运行环境的帮助下，这一运行时环境特性非常有用。
[12:27 - 12:38] 它由开源召回提供，并在处理数据依赖包或库依赖程序时提供了很大的帮助。
[12:38 - 12:46] 我相信我们的召回团队贡献了近一半的实现到开源项目中。
[12:46 - 12:47] 是的。
[12:47 - 13:06] 所以当这些跟踪服务器准备就绪时，可以选择向服务发现组件注册自己，即将来的推理请求可以直接连接到这些Triton服务器。

[13:06 - 13:21] 另外一点是你提到的，由于我们的服务集群高度自动扩展，所以在我们的平台上运行trton服务器时，它们也会自动扩展。
[13:23 - 13:29] 好的，下一个场景是为区域m应用提供服务。
[13:29 - 13:38] 这个背景是我们团队内部有一个系统叫做GPT t缓存系统。
[13:38 - 13:48] 在这个系统中，我们会尝试将历史LM响应存储在我们的向量或缓存存储中。
[13:48 - 13:57] 所以每当有新的推理请求进来时，我们首先要进行的是相似性比较。
[13:57 - 14:11] 如果缓存命中，则我们只需将预先存储的响应返回给用户；如果缓存未命中，则推理请求仍需通过模型服务管道。
[14:12 - 14:22] 在我们的保留平台中，这个聊天GPT t缓存系统可以很容易地集成。
[14:22 - 14:33] 我们需要做的就是在部署演员内部运行这个GPT缓存系统，并且仍然借助演员运行时功能。
[14:33 - 14:47] 当然，在集群中我们需要一个入口演员，它会帮助我们将每个进入的推理请求转发到GBt缓存演员。
[14:47 - 14:50] 然后我们仍然做同样的事情。
[14:50 - 14:53] 如果缓存命中，我们就快速响应。
[14:53 - 15:04] 如果缓存未命中，我们就将此请求转发到另一个在部署演员中运行的Triton服务器。
[15:06 - 15:21] 这里可以看到的一件大事是，在这张图中，GPGPD缓存演员在CPU节点上运行，而Triton服务器在GPU节点上运行。
[15:21 - 15:37] 因此，得益于资源异构结果调度，我们现在可以更明智地分配这些不同类型的演员，并优化整体资源利用率。
[15:39 - 15:42] 好的，接下来是一些新功能。
[15:42 - 15:46] 第一个是构建异步经纪人。
[15:46 - 15:58] 我们这样做是因为在大多数模型服务场景中，我们发现推理请求具有非常不同的执行时间。
[15:58 - 16:07] 因此，对于这些长时间请求，人们总是需要付出大量的同步等待开销。

[16:07 - 16:14] 我们在这里所做的就是，在服务集群中部署了一个异步代理。
[16:14 - 16:20] 当然，这个异步代理也是在一个部署角色中运行的。
[16:20 - 16:26] 这个异步代理可以接收每个传入的推理请求队列。
[16:26 - 16:38] 对于这些长请求，当结果准备好时，异步代理可以帮助我们异步地将这些结果返回给用户。
[16:40 - 17:03] 我认为这个异步代理的一大好处在于，由于它在集群内部，其他部署角色可以根据它们自身的忙碌或空闲状态从这个代理中自适应地拉取它们的推理请求。
[17:03 - 17:18] 因此，通过这样做，在每个使用Triton服务器进行模型服务的部署角色中，我们可以看到更少的队头延迟。
[17:19 - 17:35] 在我们的评估中，与基于错误的轮询推送请求分配的基线相比，我们的基于代理的方法能够提供两倍的吞吐量。
[17:38 - 17:42] 下一个功能是C++部署。
[17:42 - 17:50] 这个功能已经被广泛应用于我们的推荐和广告业务中。
[17:50 - 17:55] 这些服务对延迟敏感且需要高吞吐量。
[17:55 - 18:04] 因此，由于这些性能需求，我们的部署角色也必须具备高性能。
[18:04 - 18:15] 所以我们采用的是基于开源项目的C++部署角色，C++工作者。
[18:15 - 18:22] 这个C++工作者主要是由我们的团队贡献的。
[18:22 - 18:25] 所以感谢Gyang在这方面的努力。
[18:25 - 18:36] 好的，有了这个C++部署角色，我们做的一个大事情就是实现了C++直接入口。
[18:36 - 18:40] 它是一个高性能的RPC服务。
[18:40 - 18:54] 有了这个功能，我们的推理请求可以直接连接到我们的C++部署角色，绕过所有我之前提到的代理。
[18:56 - 19:01] 另一个大的改进是原生的Triton推理调用。
[19:01 - 19:20] 由于我们现在有C++部署角色和Triton服务器（可以被视为一个C++库），这使得它们能够被更紧密和高效地集成，而没有任何跨语言的开销。

[19:20 - 19:40] 在我们进行C++部署演员的制作时，与系统中其他C++组件协同工作，并在推荐和广告时间线上实际执行更全面的分布式系统操作。
[19:43 - 19:48] 好的，接下来我将讨论一些未来的计划。
[19:48 - 19:54] 我们首先要做的是共享部署。
[19:54 - 20:11] 这个想法的动机在于我们的推荐和搜索服务中使用了CVR或CTR模型，我们可以看到大量具有大型特征数据的项目。
[20:11 - 20:19] 而且这些特征数据量太大，无法存储在任何一个单独的工作节点上。
[20:19 - 20:30] 因此我们需要做的就是尝试将这些大数据分发到多个工作节点上。
[20:30 - 20:56] 当然，我们会创建代理部署演员，利用这个代理来帮助我们实现数据路由策略，并确保每个传入的推理请求都能被转发到一个本地有数据依赖关系的具体节点上。
[20:59 - 20:59] 好的。
[20:59 - 21:04] 所以最后一点实际上是整体性的。
[21:04 - 21:13] 我们希望提供高性能的通用AI框架来实现这一目标。
[21:13 - 21:33] 首先，我们将继续构建和完善基于开源储备的推荐平台，该平台已被证明是高度分布式的、多语言支持和可扩展的。
[21:33 - 21:40] 我们相信这可以成为许多模型服务场景的良好基础。
[21:42 - 21:52] 我们肯定会使用直接接入，并用它来构建高性能的RPC服务。
[21:52 - 22:04] 我们会广泛使用C++部署演员，因为它们能给我们带来高性能计算能力。
[22:05 - 22:16] 我们将开始着手进行共享部署，这将使我们获得高性能的本地数据访问和数据检索能力。
[22:16 - 22:26] 我们认为，当未来处理大规模模型服务问题时，这一功能将会非常关键。
[22:28 - 22:32] 所以，这就是我们今天要讲的所有内容。
[22:32 - 22:39] 正如我在一开始所说的，这项工作主要由我们的Bud团队的田戈维完成。

[22:39 - 22:43] 因此，我们将尽力在这里回答问题。
[22:43 - 22:53] 但如果无法做到，我鼓励大家给这个邮箱地址发送邮件，我相信他会给出最详细的答复。
[22:53 - 22:55] 谢谢。
[23:02 - 23:12] 那么，你们在直接接入和C++方面的工作有多少已经集成到开源项目中了？
[23:12 - 23:19] 其实它已经是开源的，但在开源社区中并不太受欢迎。
[23:19 - 23:40] 但我们大量使用它来进行推荐和广告系统，因为我们希望让整个流水线中的所有组件，包括推荐流水线，都用C++实现，以使整个流水线更加统一。
[23:42 - 23:55] 关于这一点，一个跟进问题是，在你提到的推荐流水线中，你们实际在使用Ray做什么？
[23:55 - 23:58] 因为你们使用Triton进行推理，对吧？
[23:58 - 24:04] 而且你们正在使用这个直接接入，但Ray在这个过程中扮演什么角色呢？
[24:04 - 24:07] Ray是如何帮助你们在这个领域的？
[24:07 - 24:19] 是的，我们确实使用Ray来帮助我们在部署时整合Triton依赖项。
[24:19 - 24:32] 我们还使用Ray的异构调度功能来帮助我们调度这些具有CPU依赖或GPU依赖的演员。
[24:32 - 24:40] 这些都可以很好地调度，并帮助我们提高资源利用率。
[24:46 - 24:48] 谢谢你的分享。
[24:48 - 24:50] 快速提问。
[24:50 - 24:58] 你说每周有3000多个模型部署。
[24:58 - 25:07] 我的问题是，对于一种类型的模型，平均多久更新和部署一次？
[25:07 - 25:14] 比如说，我们有一个大型语言模型，那么你们多久更新和部署一次？
[25:14 - 25:31] 嗯，我想这个问题范围挺广的，我真的不知道具体细节。所以，你应该给Ten G Wei发邮件，因为这是服务团队的一些细节。
[25:37 - 25:42] 这个部署与你选择Ray有关。
[25:42 - 25:47] 是的，这个部署与选择Ray有关。

[25:47 - 26:05] 是的，它仍然在运行。我们只需要关闭这个功能数据跨多个瓦勒笔记，但瓦勒笔记仍然基于雷，所有演员都在处理反应堆。
[26:13 - 26:19] 所以所有这些都运行在像虚拟机上，而不是Kubernetes或其他中间件。
[26:19 - 26:20] 只是虚拟机。
[26:20 - 26:23] 我们所有的这些只是运行在虚拟机上吗？
[26:23 - 26:25] 还是在Kubernetes上运行？
[26:25 - 26:35] 或者我们在云原生环境中基于Kubernetes运行我们的集群。
[26:43 - 26:48] 哦，好吧，如果没有更多问题，那么非常感谢大家。
[26:48 - 26:48] 好的。
[26:48 - 26:50] 谢谢大家。