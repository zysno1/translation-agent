---
video_id: _yu0Rtuetuc
video_url: https://www.youtube.com/watch?v=_yu0Rtuetuc
video_title: How Ray Empowered Ant Group to Deliver a Large-Scale Online Serverless Platform
created_at: 2025-01-05 01:20:25
---

# How Ray Empowered Ant Group to Deliver a Large-Scale Online Serverless Platform

### 翻译文本

[00:06 - 00:08] 大家好。

[00:08 - 00:12] 我们是来自 Ant Group 的杨松和李哲。

[00:12 - 00:17] 今天的主题是由我们团队的负责人魏才（Wei Cai）提出的。

[00:17 - 00:21] 但他今天无法到场，所以由我们来演讲。

[00:21 - 00:30] 这是我们第一次来到这里，非常高兴能够分享我们在 Ant Group 的工作。

[00:30 - 00:40] 今天的话题是如何赋能 Ant Group 构建一个大规模在线服务平台。

[00:40 - 00:40] 让我们开始吧。

[00:41 - 00:46] 首先，我想介绍一下我的公司和团队。

[00:46 - 01:00] 总结一下 Ant Group，我们有五个方向：数字支付、数字连接、数字金融、数字技术和全球化。

[01:00 - 01:16] 其中最受欢迎的应用是支付宝（Alipay），它在中国的互联网支付和金融领域处于领先地位。我的团队是 Anthree 团队。

[01:16 - 01:23] 在下一页中，我会展示一些关于我团队的历史信息。

[01:23 - 01:29] 但在这里，我想先分享一些高层次的信息。

[01:30 - 01:39] 首先，我们是 Ray 开源软件的第二大贡献者。

[01:39 - 01:56] 我们与 AnyScale 和 ResLab 合作多年，在开源社区中的贡献率超过 26%。

[01:56 - 02:13] 其次，除了开发 Ray，我们在生产环境中也有大量 Ray 的大规模应用，拥有超过 100 万个 CPU 调用。

[02:14 - 02:25] 在中国，我们还创建并运营了一个丰富的 Ray 社区。

[02:25 - 02:32] 在过去的五年里，我们每年都会举办 Ray Forward Meetup。

[02:32 - 02:52] 第五届 Ray Forward 已于去年七月结束，在这次会议上，AnyScale、CrossAI、A't 和 Bad Dance 分享了他们的工作。

[02:52 - 03:01] 我们希望 Ray 在中国也能像在美国一样流行。

[03:02 - 03:07] 接下来，让我们看看 Ray 在 Ant Group 的历史。

[03:07 - 03:16] 我们的团队成立于 2017 年，那时的 Ray 与今天有很大不同。

[03:16 - 03:31] 我们将其视为通用分布式系统，这意味着我们有许多非 AI 应用和框架。

[03:31 - 03:45] 在 Ray 开源项目中，主要关注 Python 和 AI，即以 Python 和 AI 为主导，但我们有所不同。

[03:45 - 03:55] 您可以看到，我们已经为 Ray 项目贡献了 Java 和 C++ API。

[03:55 - 04:05] 2018 年，我们的第一个上层引擎 GFlow 部署到了生产环境。

[04:05 - 04:11] GFlow 是一个流图引擎，用于支付宝的风险控制。

[04:11 - 04:29] 2019 年，另一个融合引擎部署到了生产环境，该引擎支持三种计算类型：流处理、机器学习和在线服务。

[04:29 - 04:31] 这个时间点的在线服务也是首次在 Ant Group 部署。

[04:31 - 04:40] 2020 年，鉴于业务的多样性，我们构建了一个多架构体系，可以在一个大的 Ray 集群中运行多个任务。

[04:40 - 04:51] 2021 年，Ray 更加稳定，我们与生态系统中的公司如阿里云、达摩院、中国联通和网商银行进行了更多合作。

[04:51 - 05:08] 2022 年，我们探索了隐私计算这一新场景，认为这是一个适合 Ray 的场景，因为它需要灵活的框架来支持数据和 AI 功能。

[05:08 - 05:16] 2023 年，我们的目标是构建一个通用的 AI 服务框架，统一传统的 AI、大语言模型和搜索引擎。

[05:16 - 05:22] 这就是今天的主题。

[05:22 - 05:34] 从历史时间线可以看出，Ant Group 的在线服务首次部署是在 2019 年，并集成到在线学习引擎中。

[05:34 - 05:44] 基于此，我们构建了基本的服务能力，并将其集成到 Ant Group 的基础设施中。

[05:44 - 05:54] 2021 年，我们引入了在线资源分配的新场景，这对我们提出了更高的要求，需要一个更灵活、高性能、可扩展且稳定的框架。

[05:54 - 05:59] 2022 年，我们支持了大规模在线服务平台。

[05:59 - 06:12] 当时，我们每天处理 24 万次调用，事件驱动的在线服务平台达到了 1.37 百万 PPS。

[06:12 - 06:16] 这就是我们内部的工作情况。

[06:16 - 06:24] 下面由陈介绍我们今年的最新成果。

[06:24 - 06:25] 欢迎。

[06:25 - 06:26] 好的。

[06:26 - 06:29] 谢谢杨松，大家好。

[06:29 - 06:40] 我是李涛，很高兴在这里分享我们 2023 年的最新成果。

[06:40 - 06:46] 在 Ant Group，我们已经建立了最大的推理平台。

[06:46 - 06:52] 我们的推理集群拥有 50 万个 CPU 核心和 4000 个 GPU。

[06:52 - 06:57] 昨天 Dr. Stoker 在演讲中提到了这些数字。

[06:57 - 07:04] 为了支持这些硬件，我们使用了 27,000 多个工作节点。

[07:04 - 07:14] 作为推理平台，我们在平台上每周有超过 3,000 个新的模型部署和 10 万个模型更新。

[07:14 - 07:23] 我们的推理集群高度自动扩展，每周可以主动扩展超过 3,000 次。

[07:23 - 07:32] 通过这种方式，我们将平均 CPU 利用率提高了 20%。

[07:32 - 07:51] 接下来，我将介绍一些新的应用场景和功能。

[07:51 - 07:58] 在详细介绍之前，先看一下我们的 Ray 服务架构。

[07:58 - 08:02] 它与开源 Ray 服务没有太大区别。

[08:02 - 08:07] 在这个架构中，我们有一个 Serving Keeper。

[08:07 - 08:17] 它接收所有用户客户端提交的推理任务，并将这些任务分发到各个服务集群中。

[08:17 - 08:29] 对于每个任务，Serving Keeper 需要在特定的服务集群中创建一个应用程序主节点。

[08:29 - 08:40] 这个应用程序主节点会在集群中创建多个代理和部署 Actor。

[08:40 - 08:47] 当代理准备就绪后，它们会注册到独立的服务发现组件。

[08:47 - 08:58] 用户应用程序可以通过订阅这个组件获取每个代理的位置，并选择最适合的一个发送推理请求。

[08:58 - 09:09] 在每个代理中，您需要将传入的推理请求分配给本地的部署 Actor，以便在那里完成模型推理工作。

[09:09 - 09:13] 新的应用场景之一是在 GPU 上进行模型推理。

[09:13 - 09:18] 为此，我们选择了 NVIDIA Triton。

[09:18 - 09:28] 对于不熟悉 Triton 的人来说，它是 NVIDIA 提供的单节点模型推理服务器，支持多种推理后端。

[09:28 - 09:38] 在我们的 Ray 服务系统中，Triton 服务器可以非常容易地分布部署。

[09:38 - 09:49] 我们只需要让部署 Actor 成为 Triton 引导程序，每当应用程序主节点创建一个新的部署 Actor 时，它会立即启动内部的 Triton 服务器。

[09:49 - 09:59] 通过 Actor 运行时环境的帮助，这个特性非常有用，特别是在处理数据依赖包或库依赖时。

[09:59 - 10:07] 我们的 Ray 团队为开源项目贡献了近一半的实现代码。

[10:07 - 10:16] 当这些 Triton 服务器准备就绪后，它们可以选择注册到服务发现组件，接下来的推理请求可以直接连接到这些 Triton 服务器。

[10:16 - 10:21] 由于我们的服务集群高度自动扩展，因此在平台上运行的 Triton 服务器也具有自动扩展能力。

[10:21 - 10:29] 下一个应用场景是提供 AI 模型推理服务。

[10:29 - 10:38] 在 Ant Group，我们有一个名为 GPT Cache 的系统，用于存储历史 LLM 响应。

[10:38 - 10:48] 每当有新的推理请求到来时，我们首先进行相似度比较。

[10:48 - 10:57] 如果缓存命中，则直接返回预存储的响应；如果缓存未命中，则请求仍需经过模型推理管道。

[10:57 - 11:07] 在我们的 Ray 服务平台上，GPT Cache 系统可以非常容易地集成。

[11:07 - 11:17] 我们只需要在部署 Actor 内部运行 GPT Cache 系统，并借助 Actor 运行时特性。

[11:17 - 11:27] 当然，我们需要一个入口 Actor 来将每个传入的推理请求转发给 GPT Cache Actor。

[11:27 - 11:30] 然后我们做同样的事情。

[11:30 - 11:33] 如果缓存命中，则快速响应。

[11:33 - 11:44] 如果缓存未命中，则将请求转发给另一个运行在部署 Actor 中的 Triton 服务器。

[11:44 - 11:56] 在这张图中，可以看到 GPT Cache Actors 运行在 CPU 节点上，而 Triton 服务器运行在 GPU 节点上。

[11:56 - 12:07] 通过 Ray 的异构调度，我们可以更智能地分配这些不同类型的 Actor，优化整体资源利用率。

[12:07 - 12:12] 接下来是一些新功能。

[12:12 - 12:16] 第一个是构建异步代理。

[12:16 - 12:26] 我们这样做是因为在大多数模型推理场景中，推理请求的执行时间差异很大。

[12:26 - 12:34] 对于长时间请求，通常需要大量的同步等待开销。

[12:34 - 12:40] 因此，我们在服务集群中部署了一个异步代理。

[12:40 - 12:46] 当然，这个异步代理也是一个部署 Actor。

[12:46 - 12:52] 异步代理可以接收并排队每一个传入的推理请求。

[12:52 - 13:03] 对于长时间请求，当结果准备好后，异步代理可以帮助我们将结果异步返回给用户。

[13:03 - 13:18] 通过这种方式，其他部署 Actor 可以根据自身的忙闲状态自适应地从代理中拉取推理请求。

[13:18 - 13:35] 在评估中，相比基于轮询的请求分配方法，我们的基于代理的方法吞吐量提高了两倍。

[13:35 - 13:42] 下一个功能是 C++ 部署。

[13:42 - 13:50] 这个功能已在推荐和广告服务中广泛部署。

[13:50 - 13:55] 这些服务对延迟敏感且需要高吞吐量。

[13:55 - 14:04] 因此，我们的部署 Actor 也需要高性能。

[14:04 - 14:15] 我们基于开源 Ray 的 C++ Worker 实现了 C++ 部署 Actor。

[14:15 - 14:22] 顺便说一句，C++ Worker 主要由我们的团队贡献。

[14:22 - 14:25] 感谢杨松在这方面的努力。

[14:25 - 14:36] 有了 C++ 部署 Actor，我们实现了一个高性能的直接入口。

[14:36 - 14:40] 它是一个高性能的 RPC 服务。

[14:40 - 14:54] 通过这个特性，我们的推理请求可以直接连接到 C++ 部署 Actor，绕过所有提到的代理。

[14:54 - 14:56] 另一个重要的特性是原生 Triton 推理调用。

[14:56 - 15:10] 这个特性得以实现是因为我们有 C++ 部署 Actor 和 Triton 服务器，可以更紧密高效地集成，而无需跨语言开销。

[15:10 - 15:20] 当 C++ 部署 Actor 与其他 C++ 组件一起工作时，实际上形成了一个更完整的分布式系统。

[15:20 - 15:28] 接下来谈谈未来计划。

[15:28 - 15:34] 第一个计划是共享部署。

[15:34 - 15:41] 在推荐和搜索服务中，我们经常遇到特征数据量巨大的问题。

[15:41 - 15:49] 这些特征数据太大，无法放入单个工作节点中。

[15:49 - 15:56] 因此，我们需要将这些大型特征数据分布在多个工作节点上。

[15:56 - 16:06] 我们将创建一个代理部署 Actor，并使用它来帮助我们实现路由策略，确保每个传入的推理请求都能被转发到具有本地数据依赖的特定节点。

[16:06 - 16:13] 最后，我们的目标是提供高性能的通用 AI 框架。

[16:13 - 16:33] 我们将继续基于开源 Ray 构建和完善我们的服务平台，使其成为高度分布式、多语言支持和可扩展的基础。

[16:33 - 16:40] 我们相信这对于许多模型推理场景来说是一个很好的基础。

[16:40 - 16:52] 我们将使用直接入口构建高性能的 RPC 服务。

[16:52 - 17:04] 我们将广泛使用 C++ 部署 Actor，以获得高性能计算能力。

[17:04 - 17:16] 我们将开始研究共享部署，以提高高性能本地数据访问和检索。

[17:16 - 17:26] 我们认为，在未来的大型模型推理问题中，这个特性非常重要。

[17:26 - 17:32] 这就是我们今天的全部内容。

[17:32 - 17:39] 如我在开头所说，这项工作主要由我们的伙伴团队成员魏才完成。

[17:39 - 17:43] 我们会尽力回答问题。

[17:43 - 17:53] 如果我们无法回答，请发送电子邮件至这个地址，我相信他会给出最详细的答案。

[17:53 - 17:55] 谢谢大家。

[18:02 - 18:12] 直接入口和 C++ 工作负载有多少已经集成到开源项目中？

[18:12 - 18:19] 这些功能已经是开源的，但在开源社区中并不太受欢迎。

[18:19 - 18:40] 但在生产环境中，我们在推荐和广告系统中广泛使用这些功能，因为我们希望整个推荐管道的所有组件都用 C++ 实现，使整个管道更加完整。

[18:42 - 18:55] 关于推荐管道的问题是，Ray 在其中扮演什么角色？

[18:55 - 18:58] 使用 Triton 进行推理，对吧？

[18:58 - 19:04] 您使用直接入口，但 Ray 在其中的作用是什么？

[19:04 - 19:19] 我们确实使用 Ray 的运行时环境来帮助我们集成 Triton 依赖项到部署 Actor 中。

[19:19 - 19:32] 我们使用 Ray 的异构调度来帮助我们调度 CPU 依赖和 GPU 依赖的 Actor，从而提高资源利用率。

[19:32 - 19:40] 感谢您的演讲。

[19:40 - 19:50] 快速提问：您提到每周有 3,000 多个模型部署，对于某一类模型，比如大语言模型，平均或通常的部署频率是多少？

[19:50 - 19:57] 如果我们有大语言模型，多久更新一次？

[19:57 - 20:14] 这个问题您可以发送邮件给魏才，因为这是来自服务团队的一些详细信息。

[20:14 - 20:29] 共享部署与您选择 Ray 有关吗？

[20:29 - 20:36] 是的，共享部署与 Ray 的选择有关。

[20:36 - 20:45] 我们仍然使用 Ray，只是需要将特征数据分布在多个工作节点上，但这些工作节点仍然是基于 Ray 构建的，所有的 Actor 都是 Reactor。

[20:45 - 20:55] 所有这些都是运行在虚拟机上，而不是 Kubernetes 或其他中间件上。

[20:55 - 20:57] 就是普通的虚拟机。

[20:57 - 21:00] 是运行在虚拟机上吗？

[21:00 - 21:05] 或者是运行在 Kubernetes 上？

[21:05 - 21:15] 我们确实在云原生环境中使用 Kubernetes 来运行 Ray 集群。

[21:15 - 21:25] 如果没有更多问题，非常感谢大家。

[21:25 - 21:28] 好的。

[21:28 - 21:30] 谢谢大家。