---
video_id: _yu0Rtuetuc
video_url: https://www.youtube.com/watch?v=_yu0Rtuetuc
video_title: How Ray Empowered Ant Group to Deliver a Large-Scale Online Serverless Platform
created_at: 2025-01-04 19:47:08
---

# How Ray Empowered Ant Group to Deliver a Large-Scale Online Serverless Platform

[00:06 - 00:08] 大家好。
[00:08 - 00:12] 我们是来自艺术团队的顾阳松和ZLI。
[00:12 - 00:17] 今天的主题是由我们的伙伴团队带领的TG魏才提出的。
[00:17 - 00:21] 但他今天不能来，所以我们将会作为演讲者。
[00:21 - 00:30] 这是我们第一次来到这里，我们非常高兴能够在这里分享我们的工作。
[00:30 - 00:40] 今天的话题是关于我们如何赋能艺术团队交付一个大规模在线服务平台。
[00:40 - 00:40] 让我们开始吧。
[00:41 - 00:46] 首先，我想介绍一下我的公司和我的团队。
[00:46 - 01:00] 总结一下，我们的团队有五个方向：数字支付、数字连接、数字金融、数字技术和全球化。
[01:00 - 01:16] 我们最受欢迎的应用程序是阿里佩，它在中国引领了互联网、支付和金融领域。我的团队是ANTHREE团队。
[01:16 - 01:23] 在下一页，我将向您展示很多关于我们团队的历史信息。
[01:23 - 01:29] 但在这里，我想先分享一些高层信息。
[01:30 - 01:39] 首先，我们在RAY开源软件方面贡献度排名第二。
[01:39 - 01:56] 我们与ANYSCALE和RESLAB合作多年，我们在开源部分的贡献率超过26%。
[01:56 - 02:13] 其次，除了开发速率，我们还在生产中大量应用了RAND，我们现在有超过100万次CPU调用。
[02:14 - 02:25] 而在中国，我们也拥有一个由我们团队创建和运营的丰富社区。
[02:25 - 02:32] 过去五年中，我们每年都会举办REFORWARD聚会。
[02:32 - 02:52] 第五届REFORWARD已经在过去的七月结束，在这次会议上，ANYSCALE、跨AI、AREN'T、A'T和BAD DANCE都分享了他们的作品。
[02:52 - 03:01] 所以，我们希望RAY在中国也能像在美国一样受欢迎。
[03:02 - 03:07] 让我们进入RAIN在ART中的历史部分。
[03:07 - 03:16] 我们的团队成立于2017年，这一年RAY与现在大不相同。
[03:16 - 03:31] 第三，我们认为RAY是一个通用的分布式系统，这意味着我们有很多非AI应用和框架。

[03:31 - 03:45] 你知道，在重新开源中，重新开源专注于Python和人工智能，这意味着首先关注Python，但我们也有所不同。
[03:45 - 03:55] 因此，你可以看到我们已经为reproject贡献了pi、Java和C++的API。
[03:55 - 04:05] 在2018年，我们的第一个用户播放器引擎被部署到生产环境中。
[04:05 - 04:11] 这个引擎名为gflow，它是一个流图引擎。
[04:11 - 04:17] 它用于支付宝支付中的风控。
[04:17 - 04:29] 另外在2019年，另一个融合引擎也被部署到了生产环境中。
[04:29 - 04:31] 这个引擎是基于学习的。
[04:31 - 04:40] 我们实现了三种计算类型，包括流处理、机器学习和在线服务。
[04:40 - 04:51] 所以你可以知道，这次在线服务也在艺术领域得到了部署，并且是主题相关的。
[04:51 - 05:08] 在2020年，鉴于业务多样性，我们开发了一个多架构的ruh，这意味着你可以在一个大的rec集群中运行大量的rjob。
[05:08 - 05:16] 在这个作业中，你可以支持不同的计算范式。
[05:16 - 05:22] 在2021年，系统更加稳定了。
[05:22 - 05:35] 我们与生态系统公司如阿里达摩院、中国网络银行和万杉银行等进行了更多的合作。
[05:36 - 05:45] 在2022年，我们探索了隐私计算这一新场景。
[05:45 - 05:53] 我们认为在隐私计算中，有一个灵活的框架来支持常见的数据功能和AI是有益的。
[05:53 - 06:07] 我们需要灵活的框架来支持常见功能数据和AI，这有很多优点。
[06:08 - 06:28] 好的，今年，即2023年，我们的目标是构建一个通用的AI服务框架，在这个框架中，我们希望统一传统的大型语言模型和搜索引擎。
[06:28 - 06:32] 这就是今天的主题。
[06:32 - 06:34] 回到在线服务。
[06:34 - 06:48] 从历史时间线来看，你可以知道，2019年，这种在线服务首次在蚂蚁集团部署。
[06:48 - 06:54] 它被集成到在线学习引擎中。
[06:54 - 06:56] 依赖于此。
[06:56 - 07:05] 我们建立了基本的预留能力，并将其整合到蚂蚁集团的基础架构中。

[07:05 - 07:13] 你知道每家公司都有自己的客户基础设施，所以我们需要采用它。
[07:13 - 07:22] 在2021年，我们有另一个场景，即在线资源分配。
[07:22 - 07:34] 你可以想象，如果资源用于支付和金融，会面临什么挑战？
[07:34 - 07:44] 我们认为挑战在于我们需要一个更灵活、高性能且可扩展、稳定的框架。
[07:44 - 07:59] 幸运的是，我们在2020年基于R&E实现了这一点，并在2022年支持了大规模的在线调查平台。
[07:59 - 08:12] 在此期间，我们为模型提供了240,000次调用服务，我们的事件驱动式调查平台达到了137万PC TPS。
[08:12 - 08:16] 好的，这就是我们所有的私有工作。
[08:16 - 08:24] 接下来Chwill将介绍我们今年的最新成果。
[08:24 - 08:25] 欢迎。
[08:25 - 08:26] 好的。
[08:26 - 08:29] 谢谢，Guan，大家好。
[08:29 - 08:40] 我叫李东，非常高兴能在这里与大家分享我们在2023年的最新成果。
[08:40 - 08:46] 在End集团，我们已经建立了最大的推理平台。
[08:46 - 08:52] 我们的推理集群总共有50万CPU核心和4000个GPU核心。
[08:52 - 09:00] 我相信你们昨天已经在Dr. Stoker的Keno演讲中看到了这些数字。
[09:00 - 09:07] 为了提供这些硬件，我们总共使用了超过27000个工作站。
[09:07 - 09:14] 作为推理平台，我们的平台上部署了非常活跃的模型。
[09:14 - 09:23] 每周我们有超过3000个新模型部署，每周还有超过100000次模型更新。
[09:23 - 09:28] 我们的推理集群高度自动扩展。
[09:28 - 09:41] 因此，由于我们的产品线和支持独立自动缩放器，我们的推理集群现在每周可以主动自动扩展超过3000次。
[09:41 - 09:48] 通过这种方式，我们提高了平均CPU利用率超过20%。
[09:51 - 09:58] 所以下面我将谈谈我们生产中的新场景以及我们新增的一些功能。
[09:59 - 10:07] 在详细介绍之前，我想首先展示一下我们Reay服务架构的概览。
[10:07 - 10:12] 它与开源版本并没有太大区别。
[10:12 - 10:17] 在这个架构中我们有服务守护进程。

[10:17 - 10:29] 它接收所有来自用户客户端的服务推理任务提交，并且必须将这些服务任务分配到我们的服务集群中。
[10:29 - 10:40] 但对于每一个任务，服务守护者需要在一个特定的服务集群中创建一个相应的应用程序主控。
[10:40 - 10:47] 这个应用程序主控将在集群内部创建多个代理和部署角色。
[10:48 - 10:57] 当这些代理准备好后，它们将注册到独立的服务发现组件。
[10:57 - 11:12] 通过订阅这个组件，我们的用户应用程序可以了解每个代理的位置，并仔细选择最合适的代理来发送它们的推理请求。
[11:13 - 11:27] 在每个代理中，您需要将传入的推理请求分配给本地部署角色，在那里完成模型服务工作。
[11:29 - 11:32] 好的，那么新的场景。
[11:32 - 11:36] 第一种是在GPU上进行模型推理。
[11:36 - 11:41] 为了实现这一点，我们选择了使用Triton。
[11:41 - 11:51] 对于那些不熟悉Triton的人，它是一种视频推理的单一节点模型。
[11:51 - 12:01] 它支持多种推理后端，在我们的预留系统中，Triton服务器可以非常容易地分布。
[12:01 - 12:09] 我们需要做的就是让我们的部署角色成为Triton启动器。
[12:09 - 12:19] 因此，每当应用程序主控创建一个新的部署角色时，它会立即启动Triton服务器。
[12:19 - 12:27] 在我们演员运行环境的帮助下，这一运行环境特性非常有用。
[12:27 - 12:38] 这是由开源召回提供的，当我们处理数据依赖包或库依赖程序时，这帮助很大。
[12:38 - 12:46] 我相信我们的召回团队为开源贡献了近一半的实现。
[12:46 - 12:47] 是的。
[12:47 - 13:06] 所以当这些跟踪服务器准备就绪时，它们可以选择注册到这个发现服务组件，即将来的推理请求可以直接连接到这些Triton服务器。

[13:06 - 13:21] 另外一点是你提到的，由于我们的服务集群高度自动扩展，因此当你在我们的平台上运行trton服务器时，它们也会变得自动扩展。
[13:23 - 13:29] 好的，下一个场景是为区域m应用提供服务。
[13:29 - 13:38] 这个背景是我们团队中有一个名为GPT t cash acuh的系统。
[13:38 - 13:48] 在这个系统中，我们会尝试将历史的LM响应存储在我们的向量或缓存存储中。
[13:48 - 13:57] 所以每当有新的推理请求进来时，我们首先要做的就是进行相似性比较。
[13:57 - 14:11] 所以如果缓存命中，则我们直接返回预先存储的响应给用户；如果缓存未命中，则推理请求仍需通过模型服务管道。
[14:12 - 14:22] 在我们的保留平台中，这个聊天GPT t cash系统可以很容易地集成。
[14:22 - 14:33] 我们需要做的就是在部署角色内部运行这个GPT cash系统，并仍然利用角色运行时功能的帮助。
[14:33 - 14:47] 当然，我们需要在集群中有一个入口角色，它会帮助我们将每个传入的推理请求转发到第一个GPT cash角色。
[14:47 - 14:50] 然后我们仍然做同样的事情。
[14:50 - 14:53] 如果缓存命中，我们就快速响应。
[14:53 - 15:04] 如果缓存未命中，我们就将此请求转发到另一个在部署角色中运行的Triton服务器。
[15:06 - 15:21] 所以这里可以看到的一件大事是，在这张图中，G P gpd cash actors在CPU节点上运行，而trident服务器在GPU节点上运行。
[15:21 - 15:37] 因此，得益于资源异构结果调度，我们现在可以更明智地分配这些不同类型的actors，并优化整体资源利用率。
[15:39 - 15:42] 好的，接下来是一些新功能。
[15:42 - 15:46] 第一个功能是构建异步broker。
[15:46 - 15:58] 我们这样做是因为在大多数模型服务场景中，我们发现推理请求的执行时间差异很大。
[15:58 - 16:07] 因此，对于这些长请求，人们总是要付出大量的同步等待开销。

[16:07 - 16:14] 在这里我们所做的就是，在服务集群中部署了一个异步代理。
[16:14 - 16:20] 当然，这个异步代理也是运行在一个部署演员中的。
[16:20 - 16:26] 这个异步代理可以接收每个传入的推理请求队列。
[16:26 - 16:38] 对于这些长请求，当结果准备好时，异步代理可以帮助我们将这些结果异步返回给用户。
[16:40 - 17:03] 我认为异步代理的一大好处是，由于它位于集群内部，其他部署演员可以根据它们自身的忙碌或空闲状态从该代理中自适应地拉取推理请求。
[17:03 - 17:18] 因此，通过这样做，每个运行着Triton服务器进行模型服务的部署演员都可以看到更少的队首延迟。
[17:19 - 17:35] 在我们的评估中，与基于错误的轮询推送分配方法相比，我们的基于轮询的方法可以提供两倍的吞吐量。
[17:38 - 17:42] 下一个特性是C++部署。
[17:42 - 17:50] 这个特性已经被广泛应用于我们的推荐和广告业务中。
[17:50 - 17:55] 这些服务对延迟敏感且需要高吞吐量。
[17:55 - 18:04] 因此，由于这些性能要求，我们的部署演员也必须具有高性能。
[18:04 - 18:15] 所以我们使用了基于开源项目的C++部署演员，即C++工作者。
[18:15 - 18:22] 顺便说一句，这个C++工作者主要由我们的R团队贡献。
[18:22 - 18:25] 所以感谢Gyang在这个项目上的努力。
[18:25 - 18:36] 好的，有了这个C++部署演员，我们实现的一个重要功能是C++直接接入。
[18:36 - 18:40] 它是一个高性能的RPC服务。
[18:40 - 18:54] 利用这一功能，我们的推理请求可以直接连接到我们的C++部署演员，绕过我之前提到的所有这些代理。
[18:56 - 19:01] 另一个重要的事情是原生的Triton推理调用。
[19:01 - 19:20] 因为我们现在有C++部署演员和Triton服务器（可以看作是一个C++库），所以可以更紧密、更高效地集成，而没有任何跨语言开销。

[19:20 - 19:40] 在我们进行C++部署演员制作时，与我们推荐和广告时间线中的其他C++组件协同工作，我们实际上正在构建一个更全面的分布式系统。
[19:43 - 19:48] 好的，接下来我将谈论一些未来的计划。
[19:48 - 19:54] 我们首先要做的事情是共享部署。
[19:54 - 20:11] 这个举措的动机在于，在我们的推荐和搜索服务中使用CVR或CTR模型时，我们总是能看到大量的具有大特征尺寸的数据项。
[20:11 - 20:19] 而且这些特征数据的大小太大，无法放入任何一个单独的工作节点。
[20:19 - 20:30] 所以我们必须尝试将这些大数据量的特征数据分布在多个工作节点上。
[20:30 - 20:56] 当然，我们将创建代理部署演员，并利用这个代理来帮助我们实现数据分发路由策略，确保每个传入的推理请求都能被转发到本地有数据依赖关系的具体节点。
[20:59 - 20:59] 好的。
[20:59 - 21:04] 所以最后一件事是关于整体规划。
[21:04 - 21:13] 我们希望交付高性能的通用AI框架来实现这一目标。
[21:13 - 21:33] 首先，我们将继续建设和完善基于开源库的推荐平台，该库已被证明是高度分布式的、多语言支持和可扩展的。
[21:33 - 21:40] 我们相信这可以成为许多模型服务场景的良好基础。
[21:42 - 21:52] 我们肯定会使用直接入口并用它来构建高性能的RPC服务。
[21:52 - 22:04] 我们会广泛使用C++部署演员，因为它们能提供高性能计算能力。
[22:05 - 22:16] 我们将开始着手处理共享部署，这将给我们带来高性能的本地数据访问和数据检索。
[22:16 - 22:26] 我们认为，当未来面临大规模模型服务问题时，这一特性将变得非常关键。
[22:28 - 22:32] 所以，今天的内容基本上就到这里了。
[22:32 - 22:39] 正如我在一开始所说的，这项工作主要由我们团队的滕伟完成。

[22:39 - 22:43] 好的，我们会尽力在这里回答问题。
[22:43 - 22:53] 但如果不能回答的话，我鼓励大家给这个邮箱地址发送邮件，我相信他会给出最详细的解答。
[22:53 - 22:55] 谢谢。
[23:02 - 23:12] 那么你们所做的直接入口和C++工作有多少已经集成到开源项目中了？
[23:12 - 23:19] 它已经是开源的，但实际上在开源社区并不太受欢迎。
[23:19 - 23:40] 但我们生产中大量使用它，因为我们在推荐系统和广告系统中使用它，我们希望我们的整个流程中的所有组件，即推荐流程中的所有组件都用C++实现，以使整个流程更加完整。
[23:42 - 23:55] 关于这一点的一个后续问题是，在你刚刚提到的推荐流程这个领域里，你们实际在用ray做什么？
[23:55 - 23:58] 因为你们正在使用Triton进行推理，对吧？
[23:58 - 24:04] 你们也在使用这个直接入口，但ray在那里扮演什么角色？
[24:04 - 24:07] ray是如何帮助你们在这个领域的？
[24:07 - 24:19] 是的，我们确实使用ray来帮助我们在部署actor时整合Triton依赖项。
[24:19 - 24:32] 我们还使用ray异构调度来帮助我们调度这些actor，无论是CPU依赖型还是GPU依赖型。
[24:32 - 24:40] 这些都可以很好地被调度，并帮助我们提高资源利用率。
[24:46 - 24:48] 谢谢您的分享。
[24:48 - 24:50] 快速提问。
[24:50 - 24:58] 您提到每周有3000多个模型部署。
[24:58 - 25:07] 我的问题是，对于一种类型的模型，平均或通常的部署频率是多少？
[25:07 - 25:14] 比如说，我们有一个大型语言模型，那么你们多久更新和部署一次？
[25:14 - 25:31] 是的，这个问题你可能需要向ten G Wei发邮件询问，因为这是服务团队的一些细节信息。
[25:37 - 25:42] 这个问题是关于ray部署相关的。
[25:42 - 25:47] 是的，这是一个关于选择ray的部署相关问题。

[25:47 - 26:05] 是的，它仍然在运行。我们只需要关闭这个功能数据跨多个沃克笔记，但沃克笔记仍然基于Ray，并且所有的演员都在处理反应器。
[26:13 - 26:19] 所以所有这些都运行在像虚拟机上，而不是Kubernetes或其他中间的东西。
[26:19 - 26:20] 只是虚拟机。
[26:20 - 26:23] 我们所说的这一切只是运行在虚拟机上吗？
[26:23 - 26:25] 还是运行在Kubernetes上？
[26:25 - 26:35] 还是说我们在云原生环境中，基于Kubernetes运行我们的集群？
[26:43 - 26:48] 哦，如果再没有其他问题的话，非常感谢大家。
[26:48 - 26:48] 好的。
[26:48 - 26:50] 谢谢大家。