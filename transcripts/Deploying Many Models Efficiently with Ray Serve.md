# Deploying Many Models Efficiently with Ray Serve

感谢Seehan的介绍。今天的演讲将分为三个部分，每个部分介绍Ray Serve中不同的多模型服务解决方案。虽然你可以根据自己的需求任意组合这些方法，但首先我们会深入探讨模型组合。

最近我们看到的一个大趋势是，越来越多的应用需要多个模型来进行推理，而不仅仅是单个模型。一些常见的例子包括语音转录，这通常需要多个模型来处理单个请求；还有计算机视觉，这也通常需要多种图像处理模型，如分类器或检测器来处理单个请求。然而，使用多个模型也带来了很多挑战。首先是硬件资源的有效利用，这意味着你有一定数量的CPU和GPU计算资源，如何尽可能高效地使用它们，特别是在你有不同硬件需求的异构模型时。特别是随着大型语言模型（LLM）的兴起，目前存在严重的GPU短缺，因此每一个GPU都很重要。能够在应用中的模型之间共享GPU资源变得尤为重要。此外，能够独立扩展应用中的各个模型也很重要，尤其是当不同模型有不同的延迟或流量模式时。还有操作开销的问题，这些都是在开发或应用运行生产环境时非常重要的。测试你的应用应该简单，可观测性和监控在生产环境中非常重要，以了解应用的运行状况或是否有问题。并且能够独立升级应用的不同部分也应该灵活。但是一旦你在应用中添加了更多模型，所有这些都变得更加复杂。

让我们更深入地看一下这里展示的计算机视觉示例。假设你以原始图像作为输入，进行预处理，然后将预处理的数据通过分类器和检测器模型，最后运行一些自定义业务逻辑来决定最终返回给客户端的输出。我们将使用这个作为接下来几张幻灯片的参考示例。

那么，如果不使用Ray Serve，你可能会如何解决我们提到的这些挑战呢？你可能会尝试的第一件事是单体架构方法，即将所有模型放入一个盒子中。你可以将模型放入容器中，作为一个整体一起扩展，这就是你的服务。但是这里有一个大问题是，你无法独立扩展应用的一部分，因为所有东西都被打包在一起并粘合为一个整体。同样，你无法独立升级，如果你升级了应用的一部分，其他部分也被迫更新，这使得升级过程既非常冒险又非常昂贵。

接下来你可能会尝试将模型分离成单独的微服务。你可以有一个API网关用于访问控制，微服务之间会有通信，因为每个请求都需要多个模型进行推理。现在你可以独立扩展每个微服务。正如我们所说，有独立扩展，并且你可以独立升级一个微服务而不影响其他模型。但正是因为一切都被分隔成各自的系统，你不能再在模型之间共享资源。你必须设置很多东西，比如微服务之间的通信，可能每个微服务都有自己的数据库，监控和可观测性也需要分别设置。端到端测试你的应用也更加复杂，因为你必须部署多个子系统来测试你的应用。所以这种方法也有很多缺点。

这就是为什么我们在Ray中构建了一个结合了微服务和模型组合优势的功能。在Ray Serve中，一个应用由多个组合在一起的模型组成。每个模型可以有自己的硬件资源需求。例如，有些可能运行在GPU上，有些可能是仅CPU，有些甚至可以同时使用两者。你还可以独立自动扩展应用中的模型。这意味着如果应用中的某个模型成为瓶颈，你可以为其分配更多资源，而不是必须一起扩展所有内容。它还在进程级别进行扩展，这更加灵活，而不是在容器级别，这是微服务方法所做的。这意味着当你扩展应用时，你不必一定添加更多节点。你可以在单个节点上添加更多模型副本，直到最大化该节点的资源利用率。最后，使用Ray的独特之处在于我们可以使用分数资源。例如，如果单个模型使用半个GPU，拥有三个副本意味着你可以在两个GPU上调度所有三个副本，甚至可以用剩余的空间为另一个模型。

现在让我们看看如何使用模型组合来完成这个计算机视觉示例。你获取图像，进行预处理，将其发送到分类器和检测器模型，最后运行自定义业务逻辑。这就是你的整个多模型应用。请注意，当我们逐步添加组件到应用中时，我们也展示了你需要在右侧Python文件中添加的内容。重点是你可以通过单个Python文件定义并链接整个应用，而这正是你将应用部署到Ray集群所需的一切。

我们可以看一下这个应用的资源分配示例。分类器可能每个需要1个CPU和三分之一的GPU。预处理通常在CPU上运行，因此我们可以将这两个部署放在具有4个CPU和1个GPU可用的节点上。然后，检测器和业务逻辑可能也在CPU上运行，因此你可以将这两个放在具有2个CPU可用的第二个节点上。因此，在你的应用中很容易在模型之间共享资源。

在一个类似的现实世界用例中，Samsara从我们提到的微服务架构切换到使用Ray Serve模型组合，成功节省了50%的ML基础设施成本。

现在让我们回顾一下我们开始时提到的挑战。正如我们所提到的，在应用中很容易在模型之间共享资源，并且你可以独立扩展应用中的模型。至于操作开销，由于一切都在同一个集群上，测试你的应用非常容易，并且为整个Ray集群设置监控和可观测性也非常简单。但如果我们局限于单一应用，这里缺少的是独立升级。如果你更新了应用的一部分，仍然需要更新应用的其他部分，这也是我们进入第二部分讨论多应用的原因。

正如我们提到的，单个应用与模型组合并不适用于所有用例。假设你有一个从事计算机视觉模型的机器学习团队，专注于自动驾驶。但这些模型在夜间可能表现不佳，因此你有另一个团队专门从事夜间算法。理想情况下，这些都应该在同一集群上，以便车辆可以在夜间切换到专用算法。你可能还有另一个团队从事暴风雪或暴雨算法，激光雷达和雷达对于测量汽车与其他道路上物体之间的精确距离非常重要。理想情况下，所有这些都应该在同一集群上，因为它们服务于相同的用例。但它们可能存在于不同的代码库中，并且肯定由不同的团队管理。如果我们使用模型组合将所有这些组合成一个单一组，它们将共享相同的升级生命周期。这意味着如果一个团队想要更改其生产中的模型，其他团队管理的模型也将被迫更新。这使得升级过程既风险高、成本高，而且总体上非常复杂。你甚至可能需要另一个团队来管理跨机器学习团队的部署，确保部署过程中不出问题。这就是为什么我们增加了多应用功能，建立在模型组合之上。你的应用仍然可以由组合在一起的模型组成，但现在你可以在同一个Ray集群上拥有多个应用。每个应用都是自己的端点，有自己的升级生命周期。你可以轻松添加、删除或更新应用，而不用担心影响集群上的其他模型。同时，你仍然享有高效灵活的资源共享的好处。

让我们快速浏览一个多应用的真实世界用例。AnyScale端点是AnyScale托管的API端点，用于LLM推理和微调。最近，Meta AI发布了Llama系列模型，性能非常好。假设它刚刚发布几天前，我们希望将其添加到AnyScale端点，供用户试用和微调。假设你想将70亿参数的模型添加到AnyScale端点，只需将其添加到配置文件并部署到集群。这会将其加载到你的集群上，准备好为用户提供服务。你还可以添加更多模型，如3D模型，或者假设你也可以删除它并替换为7D模型。所有这些都可以通过修改Serve配置文件中的条目来实现。请注意，7B模型在整个过程中继续提供服务，无论集群上的其他应用发生了什么。

再次回顾我们开始时提到的挑战。正如我们所提到的，单个应用与模型组合已经提供了许多好处，如高效的资源分配和独立扩展模型，以及测试应用非常容易。可观测性和监控只需要为整个集群设置一次。但缺少的是独立升级。使用多应用，你可以将集群上的模型分组为对你有意义的组。例如，如果它们已经在不同的代码库中，或者由不同的团队管理，或者根据你的任何其他要求。你可以形成这些组，并独立更新这些组。

接下来我将交给Sihuan继续剩下的演讲。感谢Cindy深入探讨了模型组合和多应用用例。在之前的场景中，我们通常一次性将所有模型加载到服务器集群中进行服务。但随着LM用例的出现，我们需要服务大量模型，这需要比提供商能提供的更多资源。为了支持这种场景，我们引入了一种新的Reserve API，称为多路复用。

在介绍API之前，我们先看一个简单的例子，如未缩放的端点或Firefox AI。我们希望支持不同的开源模型，例如不同参数数量的Llama模型。更重要的是，我们希望支持不同客户的模型以满足他们自己的业务用例。这对支持这种用例有两个挑战。一是有限的硬件资源，通常你无法一次性将所有模型加载到集群中。一是非常昂贵，尤其是对于GPU硬件。二是对于不活跃的模型，加载到内存中而不使用是非常低效的。第二个挑战是高推理延迟。如果你总是加载模型，你的在线推理服务将始终受到冷启动时间的影响。

那么，没有多路复用的情况下是什么样的呢？通常我们将模型放入S3，用户指定模型ID并通过HTTP请求发送到集群。集群代理接收此请求，假设这个例子中集群中有两个副本。代理会随机选择一个副本来处理此请求。假设选择了副本一，我们从S3加载模型，进行推理并将结果返回给客户端。如果客户端继续发送模型一的请求，即使代理不知道模型ID位于哪个副本，代理可能会选择副本二来处理请求。这意味着你必须再次从S3加载模型一到不同的副本中以处理请求。对于模型二和模型三也是如此。想象一下，如果你有很多模型，你会有大量的模型在S3上。你最终不得不频繁加载模型，导致在线推理的代码启动时间非常高。