---
video_id: _yu0Rtuetuc
video_url: https://www.youtube.com/watch?v=_yu0Rtuetuc
video_title: How Ray Empowered Ant Group to Deliver a Large-Scale Online Serverless Platform
created_at: 2025-01-04 20:10:50
---

# How Ray Empowered Ant Group to Deliver a Large-Scale Online Serverless Platform

[00:06 - 00:08] 大家好。
[00:08 - 00:12] 我们是来自艺术组的顾阳松和ZLI。
[00:12 - 00:17] 今天的话题是由我们团队的组长魏才带领的。
[00:17 - 00:21] 但他今天不能来，所以我们将会担任演讲者。
[00:21 - 00:30] 这是我们第一次来到这里，我们非常高兴能在这里分享我们的工作。
[00:30 - 00:40] 今天的话题是关于我们如何赋能艺术组交付一个大规模在线服务平台。
[00:40 - 00:40] 让我们开始吧。
[00:41 - 00:46] 首先，我想介绍一下我的公司和我的团队。
[00:46 - 01:00] 总结一下，我们集团有五个方向：数字支付、数字连接、数字金融、数字技术和全球化。
[01:00 - 01:16] 我们最受欢迎的应用程序是阿里，它在中国引领了互联网、支付和金融行业。我的团队是ANT THREE团队。
[01:16 - 01:23] 在下一页，我将向你们展示很多关于我的团队的历史信息。
[01:23 - 01:29] 但在那之前，我想先分享一些高层次的信息。
[01:30 - 01:39] 首先，我们是第二大为Ray开源软件贡献的团队。
[01:39 - 01:56] 我们与任何规模和ResLab合作多年，并且我们在开源记录部分的贡献超过了26%。
[01:56 - 02:13] 其次，除了开发Ray之外，我们还在生产中应用了大量的Ray。我们现在有超过1百万次CPU调用。
[02:14 - 02:25] 此外，在中国，我们也拥有一个由我们团队创建和运营的丰富社区。
[02:25 - 02:32] 而且在过去五年里，我们每年都会举办Reforward Meetup。
[02:32 - 02:52] 第五届Reforward Meetup在上个月已经结束，在这次会议上，AnyScale、Cross AI、A&T和Bad Dance都分享了他们的作品。
[02:52 - 03:01] 所以，我们希望Ray在中国也能像在美国一样受欢迎。
[03:02 - 03:07] 让我们进入Rain在Art历史的部分。
[03:07 - 03:16] 我们的团队成立于2017年，这一年Ray与现在有所不同。
[03:16 - 03:31] 我们认为它是一个通用的分布式系统，这意味着我们有很多非AI应用程序和框架。

[03:31 - 03:45] 众所周知，Reopen Source 专注于 Python 和 AI，这意味着首先关注 Python，其次是 AI，但我们有所不同。
[03:45 - 03:55] 因此，您可以知道我们已经为 Reproject 贡献了 Python、Java 和 C++ 的 API。
[03:55 - 04:05] 在 2018 年，我们的第一个用户层引擎部署到了生产环境中。
[04:05 - 04:11] 这个引擎名为 GFlow，是一个流式图引擎。
[04:11 - 04:17] 它用于支付宝支付中的风控场景。
[04:17 - 04:29] 在 2019 年，另一个融合引擎在生产中部署。
[04:29 - 04:31] 这个引擎是基于学习的。
[04:31 - 04:40] 我们完成了三种计算类型，包括流式处理、机器学习和在线服务。
[04:40 - 04:51] 所以您可以看出，这次在线服务也是首次部署到 ART 中，并且是主题相关的。
[04:51 - 05:08] 在 2020 年，鉴于业务的多样性，我们实现了多架构的 Ruh，这意味着您可以在一个大的 Rec 集群中运行多个 Rjob。
[05:08 - 05:16] 在这个任务中，您可以支持不同的计算范式。
[05:16 - 05:22] 在 2021 年，系统变得更加稳定。
[05:22 - 05:35] 我们与生态系统公司如阿里达摩院、中国网络和万商银行等进行了更多的合作。
[05:36 - 05:45] 在 2022 年，我们探索了隐私计算这一新场景。
[05:45 - 05:53] 我们认为隐私计算对于 R 是一个好的应用场景。
[05:53 - 06:07] 因为在隐私计算中，我们需要灵活的框架来支持常见的功能数据和 AI，并且有许多优点。
[06:08 - 06:28] 好的，今年即 2023 年，我们旨在构建一个通用的 AI 服务框架。在这个框架中，我们希望统一传统 AI 大规模语言模型和搜索引擎。
[06:28 - 06:32] 这就是今天的主题。
[06:32 - 06:34] 回到在线服务。
[06:34 - 06:48] 从历史时间线来看，您可以知道在线服务最早在 2019 年部署在蚂蚁集团。
[06:48 - 06:54] 它与在线学习引擎集成。
[06:54 - 06:56] 依赖于此。
[06:56 - 07:05] 我们构建了基本的预留能力，并将其集成到 ART 集团的基础架构中。

[07:05 - 07:13] 您知道每家公司都有其客户基础设施，因此我们需要采纳它。
[07:13 - 07:22] 在2021年，我们还有另一个场景，即在线资源分配。
[07:22 - 07:34] 想象一下，如果资源是用于支付和金融，会面临哪些挑战？
[07:34 - 07:44] 我们认为这些挑战在于需要一个更加灵活、高性能且可扩展、稳定的框架。
[07:44 - 07:59] 幸运的是，我们在2020年基于re实现了这一目标，并在2022年支持了大规模在线服务。
[07:59 - 08:12] 在此期间，我们的服务模型调用量达到了240,000次，事件驱动的服务平台达到了1.37百万PC TPS。
[08:12 - 08:16] 好的，这就是我们所有的私有工作。
[08:16 - 08:24] 下面我将介绍我们今年的最新成果。
[08:24 - 08:25] 欢迎。
[08:25 - 08:26] 好的。
[08:26 - 08:29] 谢谢，Guam，大家好。
[08:29 - 08:40] 我叫李同，非常高兴在这里分享我们在2023年的最新成果。
[08:40 - 08:46] 在端到端组，我们已经建立了最大的推理平台。
[08:46 - 08:52] 我们的推理集群总共有50万CPU核心和4000个GPU核心。
[08:52 - 09:00] 我相信你们昨天已经在Dr. Stokers Keno的演讲中看到了这些数字。
[09:00 - 09:07] 为了部署这些硬件，我们总共使用了超过27,000个工作节点。
[09:07 - 09:14] 作为一个推理平台，我们的平台上有着非常活跃的模型部署。
[09:14 - 09:23] 每周我们有超过3000个新的模型部署，每周有超过100,000个模型更新。
[09:23 - 09:28] 我们的推理集群高度自动化可扩展。
[09:28 - 09:41] 因此，得益于我们的产品团队和独立的自动扩展器，我们的推理集群现在可以每周主动扩展超过3000次。
[09:41 - 09:48] 通过这种方式，我们提高了平均CPU利用率超过20%。
[09:51 - 09:58] 接下来我将讨论我们生产中的新场景和一些新功能。
[09:59 - 10:07] 在详细介绍之前，我想首先展示一下我们Reay服务架构的概述。
[10:07 - 10:12] 它与开源版本没有太多不同。
[10:12 - 10:17] 在这个架构中，我们有服务守护进程。

[10:17 - 10:29] 它接收所有来自用户客户端的服务推理任务提交，并且必须将这些服务任务分配到我们的服务集群中。
[10:29 - 10:40] 但对于每个任务，服务守护进程需要在一个特定的服务集群中创建一个相应的应用程序主控。
[10:40 - 10:47] 这个应用程序主控将在集群内创建多个代理和部署演员。
[10:48 - 10:57] 当这些代理准备就绪时，它们将向独立的服务发现组件注册自己。
[10:57 - 11:12] 通过订阅该组件，我们的用户应用可以获知每个代理的位置，并仔细选择最合适的代理来发送其推理请求。
[11:13 - 11:27] 而在每个代理中，必须为传入的推理请求分配本地部署演员，在那里完成模型服务工作。
[11:29 - 11:32] 好的，新的场景。
[11:32 - 11:36] 第一种是进行GP S上的模型推理工作。
[11:36 - 11:41] 为了实现这一点，我们选择了使用Triton。
[11:41 - 11:51] 对于那些不熟悉Triton的人，它是一个视频单节点模型推理服务器。
[11:51 - 12:01] 它支持多种推理后端，在我们的保留系统中，Triton服务器可以非常容易地进行分布。
[12:01 - 12:09] 我们所需要做的就是让部署演员成为Triton启动器。
[12:09 - 12:19] 因此，每当应用程序主控创建一个新的部署演员时，它将立即启动Triton服务器。
[12:19 - 12:27] 在我们演员运行环境的帮助下，这个运行时环境特性非常有用。
[12:27 - 12:38] 它由开源召回库提供，并在处理数据依赖包或库依赖程序时提供了很大的帮助。
[12:38 - 12:46] 我相信我们的召回团队为开源贡献了近一半的实现。
[12:46 - 12:47] 是的。
[12:47 - 13:06] 所以当这些跟踪服务器准备就绪时，它们可以选择向这个发现服务组件注册自己，而即将到来的推理请求可以直接连接到这些Triton服务器。

[13:06 - 13:21] 有一点需要提到的是，由于我们的服务集群具有高度自动扩展性，因此在我们的平台上运行 trton 服务器时，它们也会变得自动可扩展。
[13:23 - 13:29] 好的，接下来是处理区域 m 应用程序的服务场景。
[13:29 - 13:38] 这个背景是我们团队中有一个名为 GPT t 现金存储（GPT t cash storage）的系统。
[13:38 - 13:48] 在该系统中，我们会尝试将历史的 LM 响应存储在向量或现金存储中。
[13:48 - 13:57] 因此，每当有新的推理请求进来时，我们首先进行相似性比较。
[13:57 - 14:11] 如果缓存命中，则我们只需将预存储的响应返回给用户；如果缓存未命中，则推理请求仍需通过模型服务管道。
[14:12 - 14:22] 在我们的保留平台中，这个聊天系统——GPT t 现金系统可以很容易地集成。
[14:22 - 14:33] 我们只需要在部署角色内部运行这个 GPT 现金系统，并且仍然借助角色运行时功能。
[14:33 - 14:47] 当然，我们需要在集群中有一个入口角色（ingress role），它会帮助我们将每个传入的推理请求转发到 GBT 现金角色。然后我们仍然执行相同的操作。
[14:47 - 14:50] 如果缓存命中，则我们进行快速响应。
[14:50 - 14:53] 如果缓存未命中，则我们将请求转发到另一个在部署角色中运行的 Triton 服务器。
[15:06 - 15:21] 在这张图中可以看到一个重要的事情：G P GPD 现金角色在 CPU 节点上运行，而 Triton 服务器在 GPU 节点上运行。
[15:21 - 15:37] 多亏了资源异构结果调度，我们现在可以更明智地分配这些不同类型的角色，从而优化整体资源利用率。
[15:39 - 15:42] 好的，接下来是一些新功能。
[15:42 - 15:46] 第一个是构建异步代理（asynbroker）。
[15:46 - 15:58] 我们这样做是因为在大多数模型服务场景中，我们发现推理请求的执行时间各不相同。
[15:58 - 16:07] 因此，对于这些长时间请求，人们总是不得不支付大量的同步等待开销。

[16:07 - 16:14] 我们在这里部署了一个异步代理在服务集群中。
[16:14 - 16:20] 当然，这个异步代理也是运行在一个部署Actor中。
[16:20 - 16:26] 这个异步代理可以接收每个传入的推理请求队列。
[16:26 - 16:38] 对于这些长请求，当结果准备好时，异步代理可以帮助我们异步地将这些结果返回给用户。
[16:40 - 17:03] 我认为这个异步代理的一个重要优势是，由于它位于集群内部，其他部署Actor可以根据它们自身的忙碌或空闲状态从该代理中自适应地拉取推理请求。
[17:03 - 17:18] 通过这样做，在每个运行Triton服务器进行模型推理的部署Actor中，我们可以看到更少的队首延迟。
[17:19 - 17:35] 因此，在我们的评估中，与基于错误的轮询推送请求分配方法相比，基于代理的方法可以提供两倍的吞吐量。
[17:38 - 17:42] 下一个功能是C++部署。
[17:42 - 17:50] 这个功能已经在我们的推荐和广告业务中广泛部署。
[17:50 - 17:55] 这些服务对延迟敏感且需要高吞吐量。
[17:55 - 18:04] 因此，由于这些性能需求，我们的部署Actor也必须具有高性能。
[18:04 - 18:15] 所以我们使用了基于开源竞赛的C++Worker来实现C++部署Actor。
[18:15 - 18:22] 另外，这个C++Worker主要由我们的团队贡献。
[18:22 - 18:25] 所以感谢Gyang为此付出的努力。
[18:25 - 18:36] 好的，有了这个C++部署Actor，我们做了一件大事是实现了C++直接入口。
[18:36 - 18:40] 这是一个高性能的RPC服务。
[18:40 - 18:54] 通过这个功能，我们的推理请求可以直接连接到我们的C++部署Actor，绕过我之前提到的所有这些代理。
[18:56 - 19:01] 另一件大事是原生的Triton推理调用。
[19:01 - 19:20] 由于我们现在有了C++部署Actor和Triton服务器（可以视为一个C++库），因此可以更紧密且高效地集成，而没有任何跨语言开销。

[19:20 - 19:40] 当我们制作 C++ 部署 Actors 并与其他推荐系统和广告时间线中的 C++ 组件协同工作时，实际上是在进行一个更全面的分布式系统部署。
[19:43 - 19:48] 好的，接下来我将讨论一些未来的计划。
[19:48 - 19:54] 我们首先要做的事情是共享部署。
[19:54 - 20:11] 这个想法的动机在于我们的推荐和搜索服务中，使用了 CTR 或 CVR 模型，我们可以看到许多具有大量特征数据的项目。
[20:11 - 20:19] 而且这些特征数据量太大，无法被单个工作节点容纳。
[20:19 - 20:30] 因此，我们必须尝试将这些大型特征数据分布在多个工作节点上。
[20:30 - 20:56] 当然，我们将创建代理部署 Actors，并使用这些代理来帮助我们实现数据分流策略，确保每个传入的推理请求能够被转发到一个本地可用数据依赖的具体节点。
[20:59 - 20:59] 好的。
[20:59 - 21:04] 所以最后一点是整体性的。
[21:04 - 21:13] 我们希望提供高性能的通用 AI 框架来实现这一目标。
[21:13 - 21:33] 首先，我们将继续构建和完善基于开源框架的推荐平台。该框架已经被证明是高度分布式的、多语言支持的和可扩展的。
[21:33 - 21:40] 我们相信这可以成为许多模型服务场景的良好基础。
[21:42 - 21:52] 我们肯定会使用直接接入（Direct Ingress）来构建高性能的 RPC 服务。
[21:52 - 22:04] 我们将广泛使用 C++ 部署 Actors，因为它们能为我们提供高性能计算能力。
[22:05 - 22:16] 我们还将开始着手于这种共享部署，它能为我们提供高性能的本地数据访问和数据检索。
[22:16 - 22:26] 我们认为，当我们在未来处理大规模模型服务问题时，这一功能将非常关键。
[22:28 - 22:32] 所以，这就是我们今天的所有内容。
[22:32 - 22:39] 正如我在一开始所说，这项工作主要由我们的 BUD 团队的 Ten G Wei 完成。

[22:39 - 22:43] 我们会尽力在这里回答问题。
[22:43 - 22:53] 如果我们不能回答，我鼓励大家发送邮件到这个地址，我相信他可以给出最详细的答案。
[22:53 - 22:55] 谢谢。
[23:02 - 23:12] 关于直接接入（Ingress）和你们在C++工作中集成到开源的部分，有多少已经被整合进去了？
[23:12 - 23:19] 它已经是开源的了，但实际上在开源社区中并不太受欢迎。
[23:19 - 23:40] 但是我们在生产环境中大量使用它，因为在推荐和广告系统中。我们希望在推荐流水线的所有组件都用C++实现，以使整个流水线更加整体化。
[23:42 - 23:55] 关于这一点的一个后续问题是，在您刚刚提到的推荐流水线中，您实际上是如何使用Ray的？
[23:55 - 23:58] 因为推理是使用Triton进行的，对吧？
[23:58 - 24:04] 而且您正在使用这个直接接入（Ingress），但Ray在这个场景中扮演什么角色呢？
[24:04 - 24:07] Ray是如何帮助您的？
[24:07 - 24:19] 是的，我们确实使用Ray异构环境来帮助我们整合Triton依赖项在我们的部署Actor中。
[24:19 - 24:32] 我们使用Ray异构调度来帮助我们调度这些Actor，无论是CPU依赖还是GPU依赖的Actor。
[24:32 - 24:40] 这些Actor都能很好地被调度，并帮助我们提高资源利用率。
[24:46 - 24:48] 谢谢您的分享。
[24:48 - 24:50] 快速提问。
[24:50 - 24:58] 您提到每周有3000多个模型部署。
[24:58 - 25:07] 我的问题是一类模型的平均或通常的部署频率是多少？
[25:07 - 25:14] 比如说，对于大型语言模型（Large Language Model），您多久更新并部署一次？
[25:14 - 25:31] 是的，这个问题您应该给Ten G Wei发邮件询问，因为这是来自服务团队的一些细节。
[25:37 - 25:42] 这是一个与Ray选择相关的共享部署问题。
[25:42 - 25:47] 是的，这是一个与Ray选择相关的共享部署问题。

[25:47 - 26:05] 是的，我们仍然使用 Ray。我们需要在多个 Walker 节点上关闭这个特性数据，但 Walker 节点仍然基于 Ray，所有演员（actors）都被处理为反应器（reactors）。
[26:13 - 26:19] 所有这些都在虚拟机（VM）上运行，而不是在 Kubernetes 或其他任何中间件上。
[26:19 - 26:20] 只是虚拟机（VM）。
[26:20 - 26:23] 我们所有的集群都只是在虚拟机（VM）上运行吗？
[26:23 - 26:25] 还是在 Kubernetes 上运行？
[26:25 - 26:35] 不，我们在云原生环境中基于 Kubernetes 运行我们的集群。
[26:43 - 26:48] 哦，如果再没有问题的话，那非常感谢大家。
[26:48 - 26:48] 好的。
[26:48 - 26:50] 谢谢大家。