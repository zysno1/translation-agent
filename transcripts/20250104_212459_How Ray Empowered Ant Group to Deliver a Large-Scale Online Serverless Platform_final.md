---
video_id: _yu0Rtuetuc
video_url: https://www.youtube.com/watch?v=_yu0Rtuetuc
video_title: How Ray Empowered Ant Group to Deliver a Large-Scale Online Serverless Platform
created_at: 2025-01-04 21:27:54
---

# How Ray Empowered Ant Group to Deliver a Large-Scale Online Serverless Platform

### 翻译文本

#### [00:06 - 00:08]
大家好。

#### [00:08 - 00:12]
我们是来自蚂蚁集团的杨松和李哲。

#### [00:12 - 00:17]
今天的主题由我们的团队负责人魏才提出。

#### [00:17 - 00:21]
但他今天无法到场，所以我们将会作为演讲者。

#### [00:21 - 00:30]
这是我们第一次来到这里，我们很高兴能分享我们在蚂蚁集团的工作。

#### [00:30 - 00:40]
今天的主题是如何赋能蚂蚁集团交付一个大规模在线服务平台。

#### [00:40 - 00:40]
让我们开始吧。

#### [00:41 - 00:46]
首先，我想介绍一下我的公司和我的团队。

#### [00:46 - 01:00]
总结一下蚂蚁集团，有五个方向：数字支付、数字连接、数字金融、数字技术和全球化。

#### [01:00 - 01:16]
最受青睐的是支付宝，它是蚂蚁集团在中国互联网支付和金融领域的领导者。我的团队是Anthree团队。

#### [01:16 - 01:23]
在下一页我会展示很多关于我团队的历史信息。

#### [01:23 - 01:29]
但在这里，我想先分享一些高层次的信息。

#### [01:30 - 01:39]
首先，我们是贡献Ray开源软件的第二大团队。

#### [01:39 - 01:56]
我们与AnyScale和ResLab合作多年，在开源社区中贡献了超过26%的代码部分。

#### [01:56 - 02:13]
其次，除了开发Ray，我们在生产环境中也有大量大规模的应用，CPU调用超过100万次。

#### [02:14 - 02:25]
在中国，我们还拥有一个由我的团队创建和运营的丰富的中国社区。

#### [02:25 - 02:32]
过去五年里，我们每年都会举办RayForward Meetup活动。

#### [02:32 - 02:52]
第五次RayForward已于去年七月完成，在这次会议上，AnyScale、CrossAI等公司分享了他们的工作成果。

#### [02:52 - 03:01]
因此，我们希望Ray在中国也能像在美国一样受欢迎。

#### [03:02 - 03:07]
接下来，让我们进入Ray在蚂蚁集团的历史部分。

#### [03:07 - 03:16]
我的团队成立于2017年，当时的Ray与现在有很大不同。

#### [03:16 - 03:31]
我们将其视为通用分布式系统，这意味着我们有很多非AI应用和框架。

#### [03:31 - 03:45]
您知道，在Ray开源项目中，重点是Python和AI，即以Python和AI为主，但我们有所不同。

#### [03:45 - 03:55]
因此，我们可以看到，我们已经为Ray项目贡献了Java和C++ API。

#### [03:55 - 04:05]
2018年，我们的第一个用户层引擎部署到生产环境。

#### [04:05 - 04:11]
该引擎名为GFlow，是一个流图引擎。

#### [04:11 - 04:17]
它用于支付宝的风险控制。

#### [04:17 - 04:29]
2019年，另一个融合引擎被部署到生产环境。

#### [04:29 - 04:31]
该引擎是在线学习引擎。

#### [04:31 - 04:40]
我们填补了三种计算类型，包括流式处理、机器学习和在线服务。

#### [04:40 - 04:51]
因此，您可以知道，在线服务在这段时间内也首次部署到蚂蚁集团。

#### [04:51 - 05:08]
2020年，鉴于业务的多样性，我们构建了一个多架构系统，可以在一个大的Ray集群中运行多个作业。

#### [05:08 - 05:16]
在这个作业中，可以支持不同的计算范式。

#### [05:16 - 05:22]
2021年，整个系统变得更加稳定。

#### [05:22 - 05:35]
我们与生态系统中的其他公司如阿里云、中国网络和网商银行进行了更多合作。

#### [05:36 - 05:45]
2022年，我们探索了隐私计算这一新场景。

#### [05:45 - 05:53]
我们认为这是一个适合Ray的新场景，因为隐私计算需要灵活的框架来支持常见的数据和AI功能。

#### [06:08 - 06:28]
今年，我们的目标是构建一个通用的AI服务框架，将传统的AI、大语言模型和搜索引擎统一起来。

#### [06:28 - 06:32]
这就是今天的主题。

#### [06:32 - 06:34]
回到在线服务部分。

#### [06:34 - 06:48]
从历史时间线可以看出，在线服务首次于2019年部署到蚂蚁集团。

#### [06:48 - 06:54]
它被集成到在线学习引擎中。

#### [06:54 - 06:56]
基于此，

#### [06:56 - 07:05]
我们构建了基本的服务能力，并将其集成到蚂蚁集团的基础架构中。

#### [07:05 - 07:13]
每个公司都有自己的基础设施，因此我们需要进行适配。

#### [07:13 - 07:22]
2021年，我们有了新的场景——在线资源分配。

#### [07:22 - 07:34]
您可以想象，如果资源用于支付和金融，会面临哪些挑战？

#### [07:34 - 07:44]
我们认为挑战在于需要一个更灵活、高性能、可扩展且稳定的框架。

#### [07:44 - 07:59]
幸运的是，基于Ray，我们在2022年实现了这一点，支持了大规模的在线服务平台。

#### [07:59 - 08:12]
当时，我们每秒处理24万个调用，事件驱动的在线平台达到了137万次PC TPS。

#### [08:16 - 08:24]
接下来，李涛将介绍我们今年的最新成就。

#### [08:26 - 08:29]
谢谢，大家好。

#### [08:29 - 08:40]
我是李涛，很高兴在这里分享我们2023年的最新成就。

#### [08:40 - 08:46]
在蚂蚁集团，我们已经建立了最大的推理平台。

#### [08:46 - 08:52]
我们的推理集群共有50万台CPU和4000台GPU。

#### [08:52 - 09:00]
我相信昨天在Dr. Stoker的演讲中你们已经看到了这些数字。

#### [09:00 - 09:07]
为了提供这些硬件支持，我们总共使用了27000个工作节点。

#### [09:07 - 09:14]
作为推理平台，我们在平台上非常活跃地部署模型。

#### [09:14 - 09:23]
每周我们有超过3000个新模型部署和超过10万个模型更新。

#### [09:23 - 09:28]
我们的推理集群具有高度自动扩展能力。

#### [09:28 - 09:41]
得益于产品特性和独立的自动扩展器，我们的推理集群每周可以主动扩展超过3000次。

#### [09:41 - 09:48]
通过这样做，我们将平均CPU利用率提高了超过20%。

#### [09:51 - 09:58]
接下来，我将讨论我们生产中的一些新场景和新特性。

#### [09:59 - 10:07]
在详细介绍之前，我先展示一下我们的Ray Serving架构概览。

#### [10:07 - 10:12]
它与开源版本没有太大区别。

#### [10:12 - 10:17]
在这个架构中，我们有Serving Keeper。

#### [10:17 - 10:29]
它接收所有来自用户客户端的推理任务提交，并将这些任务分发到各个Serving集群。

#### [10:29 - 10:40]
对于每个任务，Serving Keeper会在特定的Serving集群中创建一个对应的应用程序主控。

#### [10:40 - 10:47]
这个应用程序主控将在集群内部创建多个代理和部署Actor。

#### [10:48 - 10:57]
当代理准备就绪时，它们会注册到独立的服务发现组件。

#### [10:57 - 11:12]
通过订阅该组件，用户应用程序可以获取每个代理的位置，并选择最适合的一个发送推理请求。

#### [11:13 - 11:27]
在每个代理中，必须将传入的推理请求分配给本地的部署Actor，模型服务工作将在那里完成。

#### [11:32 - 11:36]
第一个新场景是在GPU上进行模型推理。

#### [11:36 - 11:41]
为此，我们选择了视频Triton。

#### [11:41 - 11:51]
对于不熟悉Triton的用户，它是一个单节点模型推理引擎。

#### [11:51 - 12:01]
它支持多种推理后端，在我们的Serving系统中，Triton服务器可以非常容易地分布。

#### [12:01 - 12:09]
我们所做的只是让我们的部署Actor成为一个Triton启动器。

#### [12:09 - 12:19]
每当应用程序主控创建一个新的部署Actor时，它会立即启动内部的Triton服务器。

#### [12:19 - 12:27]
借助Actor运行时环境，这一特性非常有用。

#### [12:27 - 12:38]
它由开源Ray提供，帮助我们在处理数据依赖包或库依赖程序时提供了很大帮助。

#### [12:47 - 13:06]
当这些跟踪服务器准备好时，它们可以选择注册到服务发现组件，即将到达的推理请求可以直接连接到这些Triton服务器。

#### [13:06 - 13:21]
由于我们的Serving集群具有高度自动扩展能力，因此在我们的平台上运行Triton服务器时，它们也会变得自动扩展。

#### [13:23 - 13:29]
下一个场景是服务于Area M应用程序。

#### [13:29 - 13:38]
背景是我们有一个名为GPT Cache的系统。

#### [13:38 - 13:48]
在这个系统中，我们将尝试将历史LM响应存储在向量或缓存存储中。

#### [13:48 - 13:57]
每当有新的推理请求到来时，我们首先进行相似性比较。

#### [13:57 - 14:11]
如果命中缓存，我们只需将预存储的响应返回给用户；如果未命中，则推理请求仍需通过模型服务管道。

#### [14:12 - 14:22]
在我们的Serving平台中，这个GPT Cache系统可以非常容易地集成。

#### [14:22 - 14:33]
我们只需要在部署Actor内部运行这个GPT Cache系统，并借助Actor运行时特性。

#### [14:33 - 14:47]
当然，我们还需要一个Ingress Actor，在集群中帮助我们转发每个传入的推理请求到GPT Cache Actor。

#### [14:50 - 14:53]
如果缓存命中，我们快速响应。

#### [14:53 - 15:04]
如果缓存未命中，我们则将请求转发到另一个运行在部署Actor中的Triton服务器。

#### [15:06 - 15:21]
可以看到，在这张图中，GPT Cache Actors运行在CPU节点上，而Triton服务器运行在GPU节点上。

#### [15:21 - 15:37]
得益于Ray的异构资源调度，我们现在可以更明智地分配这些不同类型的Actor，优化整体资源利用率。

#### [15:42 - 15:46]
首先是构建异步Broker。

#### [15:46 - 15:58]
我们这样做是因为在大多数模型服务场景中，我们发现推理请求的执行时间差异很大。

#### [15:58 - 16:07]
对于长时间请求，人们总是要付出大量的同步等待开销。

#### [16:07 - 16:14]
因此，我们在Serving集群中部署了一个异步Broker。

#### [16:14 - 16:20]
当然，这个异步Broker也是运行在一个部署Actor中。

#### [16:20 - 16:26]
这个异步Broker可以接收并排队每个传入的推理请求。

#### [16:26 - 16:38]
对于长时间请求，当结果准备好时，异步Broker可以帮助我们将结果异步返回给用户。

#### [16:40 - 17:03]
一个重要的好处是，集群内的其他部署Actor可以根据自身的繁忙或空闲状态自适应地从Broker中拉取推理请求。

#### [17:03 - 17:18]
因此，在每个运行Triton服务器的部署Actor中，我们可以看到更少的头部阻塞延迟。

#### [17:19 - 17:35]
在评估中，与基线相比，我们的方法可以将吞吐量提高两倍。

#### [17:38 - 17:42]
下一个特性是C++部署。

#### [17:42 - 17:50]
这一特性已广泛应用于我们的推荐和广告服务中。

#### [17:50 - 17:55]
这些服务对延迟敏感且要求高吞吐量。

#### [17:55 - 18:04]
因此，出于性能要求，我们的部署Actor也需要高性能。

#### [18:04 - 18:15]
我们使用基于开源Ray的C++ Worker实现了C++部署Actor。

#### [18:15 - 18:22]
顺便说一句，这个C++ Worker主要由我们的团队贡献。

#### [18:25 - 18:36]
有了这个C++部署Actor，我们实现了一个高性能的直接入口。

#### [18:36 - 18:40]
它是一个高性能的RPC服务。

#### [18:40 - 18:54]
通过这一特性，我们的推理请求可以直接连接到C++部署Actor，绕过所有提到的代理。

#### [18:56 - 19:01]
另一项重要特性是原生Triton推理调用。

#### [19:01 - 19:20]
这可以通过我们现有的C++部署Actor和Triton服务器（可以视为C++库）紧密高效地集成，无需跨语言开销。

#### [19:20 - 19:40]
当我们使C++部署Actor与其他C++组件一起工作时，实际上是在构建一个更完整的分布式系统。

#### [19:43 - 19:48]
接下来，我将谈谈一些未来的计划。

#### [19:48 - 19:54]
第一件事是共享部署。

#### [19:54 - 20:11]
动机是在推荐和搜索服务中，我们总是看到大量具有大数据特征的项目。

#### [20:11 - 20:19]
这些特征数据太大，无法适应任何单个工作节点。

#### [20:19 - 20:30]
因此，我们必须将这些大数据特征分布在多个工作节点上。

#### [20:30 - 20:56]
当然，我们会创建一个代理部署Actor，并使用这个代理帮助我们实现路由策略，确保每个传入的推理请求都能转发到具有本地数据依赖的具体节点。

#### [21:04 - 21:13]
我们希望交付高性能的通用AI框架。

#### [21:13 - 21:33]
首先，我们将继续构建和完善基于开源Ray的Serving平台，它已被证明是高度分布式的、多语言支持的和可扩展的。

#### [21:33 - 21:40]
我们相信这可以为许多模型服务场景提供良好的基础。

#### [21:42 - 21:52]
我们将广泛使用直接入口，构建高性能的RPC服务。

#### [21:52 - 22:04]
我们将广泛使用C++部署Actor，因为它可以提供高性能计算能力。

#### [22:05 - 22:16]
我们将开始工作于共享部署，这可以为我们提供高性能的本地数据访问和检索。

#### [22:16 - 22:26]
我们认为这一特性在未来处理大规模模型服务问题时将非常重要。

#### [22:32 - 22:39]
如我在开头所说，这项工作主要由魏才完成。

#### [22:39 - 22:43]
我们将尽力回答问题。

#### [22:43 - 22:53]
如果无法回答，我鼓励大家发送电子邮件到这个地址，他可以提供最详细的答案。

#### [23:02 - 23:12]
那么，直接入口和C++工作有多少已经集成到开源中？

#### [23:12 - 23:19]
这些已经开源，但在开源社区中并不太流行。

#### [23:19 - 23:40]
但在生产中我们大量使用，特别是在推荐和广告系统中，因为我们希望使推荐管道中的所有组件都用C++实现，使整个管道更加完整。

#### [23:42 - 23:55]
关于推荐管道的问题，您具体是如何使用Ray的？

#### [23:55 - 23:58]
因为您使用Triton进行推理，对吗？

#### [23:58 - 24:04]
您使用直接入口，但Ray在这里扮演什么角色？

#### [24:04 - 24:07]
Ray如何帮助您？

#### [24:07 - 24:19]
我们确实使用Ray环境帮助我们将Triton依赖集成到部署Actor中。

#### [24:19 - 24:32]
我们使用Ray的异构调度来帮助我们调度这些Actor，无论是CPU依赖还是GPU依赖的Actor。

#### [24:32 - 24:40]
它们都可以很好地调度，帮助我们提高资源利用率。

#### [24:46 - 24:48]
谢谢您的演讲。

#### [24:48 - 24:50]
快速提问。

#### [24:50 - 24:58]
您提到每周有超过3000个模型部署。

#### [24:58 - 25:07]
我的问题是，对于某一类模型，比如大型语言模型，通常的部署频率是多少？

#### [25:07 - 25:14]
例如，大型语言模型多久更新一次？

#### [25:14 - 25:31]
这个问题涉及一些细节，建议您发送电子邮件给魏才，因为他了解具体的部署团队情况。

#### [25:42 - 25:47]
共享部署是否与Ray的选择有关？

#### [25:47 - 26:05]
是的，它仍然基于Ray，我们只需要将这些特征数据分布在多个工作节点上，但这些工作节点仍然是基于Ray构建的，所有Actor都是通过Ray处理的。

#### [26:13 - 26:19]
所以这一切都在虚拟机上运行，而不是Kubernetes或其他中间件。

#### [26:19 - 26:20]
只是虚拟机。

#### [26:20 - 26:23]
这都是在虚拟机上运行的吗？

#### [26:23 - 26:25]
还是在Kubernetes上？

#### [26:25 - 26:35]
实际上，我们确实在云原生环境中基于Kubernetes运行我们的Ray集群。

#### [26:43 - 26:48]
如果没有更多问题，非常感谢大家。

#### [26:48 - 26:50]
好的。

#### [26:48 - 26:50]
谢谢大家。