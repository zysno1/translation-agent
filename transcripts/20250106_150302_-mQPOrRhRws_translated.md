# Perplexity AI: How We Built the World's Best LLM-Powered Search Engine in 6 Months, w/ Less Than $4M

## 视频信息
- 视频ID: -mQPOrRhRws
- 视频标题: Perplexity AI: How We Built the World's Best LLM-Powered Search Engine in 6 Months, w/ Less Than $4M
- 视频URL: https://www.youtube.com/watch?v=-mQPOrRhRws&t=443s

## 译文
[00:02 - 00:09] 太好了，是的，谢谢你们这次来，我相信人们在这个时候会感到困倦。

[00:09 - 00:18] 希望这有点娱乐性，所以我要告诉你我们是如何思考搜索的未来。

[00:18 - 00:25] 可能是最直观和最重要的产品，每个消费者都可以使用。

[00:25 - 00:35] 我们在困惑中是如何接近它的。所以想想这个线性的故事。

[00:35 - 00:42] 我们刚刚看到谷歌就是这样工作的，我在搜索好的耳机。

[00:42 - 00:48] 有很多广告、赞助链接、SEO内容，非常累人。

[00:48 - 00:57] 然后我们只是决定，好吧，如果我们可以直接看到答案，那将是非常酷的。

[00:57 - 01:07] 并比较不同的东西，所以我们只是决定，好吧，让我们建立世界上最好的研究助理，可以回答任何问题。

[01:07 - 01:15] 然后我们最终建立了这个。这就是故事的结局。这将是非常令人失望的，对吧。就像，你会想，哦，我为什么要来听这个演讲。

[01:15 - 01:24] 但答案显然是，我希望它是这样的线性，我会认为自己像个天才或什么的。

[01:24 - 01:34] 它几乎不是这样的线性，所以这实际上是我们一年前成立时发生的事情。

[01:34 - 01:46] 我们开始研究文本到SQL，这与消费者搜索无关，事实上，如果你去风险投资公司并要求资金来研究搜索，

[01:46 - 01:58] 他们根本不会资助你，无论你有多雄心勃勃，都很难说服任何人资助你。

[01:58 - 02:07] 所以我们研究了文本到SQL，我们很幸运，像Elard Gill、Nat Friedman、Jeff Dean这样非常好的人都投资了我们。

[02:08 - 02:16] 我们真的只是对用LLMs加SQL进行企业搜索感兴趣。

[02:16 - 02:25] 我们根本不知道如何做所有这些事情，公司建设、企业，这些事情都不直观。

[02:25 - 02:36] 没有专家能回答我们知道的任何问题，所以我们只是认为建立一个能够回答我们自己的问题的员工会很棒，我们可以弄清楚。

[02:36 - 02:45] 基本上，我将展示这一切看起来非常像改装，但它不是，我将实际给你截图并展示你一切。

[02:45 - 02:55] 然后在十一月，我们为自己的朋友推出了网络搜索，我们有Discord机器人。

[02:55 - 03:04] 然后显然在十一月底，ChatGPT发布，被认为是人工智能的iPhone时刻，在那之后的一周，我们推出了Perplexity。

[03:04 - 03:14] 这就是完全一样的，我们在八月三日成立，然后在九月二十七日，我们有了这个Slack机器人。

[03:14 - 03:26] 这是为我们自己准备的，比如我们看我们问的问题，比如我们问如何启动服务器和Ruby，或者什么是SOQL，它就像Salesforce查询语言。

[03:26 - 03:33] 因为我们正在研究这些东西，比如，哦，如何搜索你的Salesforce数据，如何搜索你的HubSpot数据。

[03:33 - 03:43] 我们对这些事情一无所知，所以例如，这是我试图编写HubSpot SQL查询作为模板，你知道。

[03:43 - 03:55] 教我们的承包商如何做到这一点，因为只有我知道如何做到这一点，我才能教承包商，对吧，所以我也不知道如何做到这一点，因为这些表格对我来说没有任何意义，它们都很复杂。

[03:55 - 04:03] 有太多的东西了。人们定制了很多东西。所以没有Hubspot专家。你可以去和他们谈谈。如果有那就好了。

[04:03 - 04:14] 只回答我自己的问题的搜索引擎，显然谷歌不会回答这些问题，这就是人工智能能做什么和谷歌能做什么的区别。

[04:14 - 04:22] 所以谷歌可以给你链接。谷歌可以回答你，导航到一个网页，给你这些非常琐碎的。

[04:22 - 04:35] 实际答案对于像非常简单的事情，但它不能回答复杂的查询，比如你知道，在某个表中生命周期阶段是什么意思，或者如果我要把这个改成这个东西，

[04:35 - 04:46] 我怎么还能得到信息，就像什么，你知道，所有你必须问另一个同事或朋友或在其他地方工作的同事之类的事情。

[04:46 - 04:54] 这些事情就是人工智能真正改变了故事的地方，它正在创造一种新产品，新的市场细分。

[04:54 - 05:04] 而不是从已经存在的东西中夺取市场份额。所以我们发现这对我们的超级有用。你知道，保罗·格雷厄姆非常出名地说过这句话。

[05:04 - 05:13] Y Combinator在这方面也非常有名，你首先必须建立一些你自己和你周围的朋友，你周围的人使用的东西。

[05:13 - 05:21] 如果你连那个都没有，你就很难找到与其他人匹配的产品市场。

[05:21 - 05:32] 即使你确实有别人想要的东西，但你自己从未使用过，你也不太可能做得好。

[05:32 - 05:41] 因为你并不真的在乎，为什么那个人的问题是你的问题，对吧，因为你想通过解决他们的问题来赚钱。

[05:41 - 05:50] 那不会是一个持久的动力，所以我认为通过这个过滤器是非常重要的。

[05:50 - 05:58] 对于你，你自己，以及你自己公司里的人开始使用它，你会学到很多东西。

[05:58 - 06:07] 这是另一个例子。在我开始这个之前，我没有公司建设经验，而且。

[06:07 - 06:19] 在某个时候我意识到，你知道，当我试图招募人时，他们会问我，你们提供健康保险吗，就像我们甚至没有为任何人提供健康保险一样，没有任何政策，我们甚至没有，

[06:19 - 06:30] Gusto或just works，这些都没有，所以当你去挑选这些东西时，我对这些术语的意思一无所知，所有这些东西都像扣除额，你知道，他们喜欢混淆你，对吧？

[06:30 - 06:40] 所以再次，谷歌在这方面很糟糕，如果你在那里问这些问题，你只会得到SEO链接和所有这些保险公司只是付给谷歌这么多钱，

[06:40 - 06:51] 让他们的网站上线，这并不能真正解决你的问题，所以我开始大量使用它，然后我们最终意识到的是。

[06:52 - 07:02] 当我们问这些问题时，我无法信任答案，所以当我去找以前做过这件事的人时，他们会告诉我，不，不，不，你说的不对。

[07:02 - 07:13] 显然，你知道，事后看来，这是显而易见的，但你需要连接到真实的数据，否则你不能信任答案。

[07:13 - 07:25] 机器人，那只是语言模型，所以你需要把它插入到搜索索引中，然后我的联合创始人，丹尼斯，他是我们的CTO，他只是随便说，

[07:25 - 07:35] 我添加了一些必应搜索和摘要。然后我们能够问一些真实的问题，比如这里发生了什么？就像当时是埃隆在。

[07:35 - 07:44] 接管推特的时候，所以他问，埃隆解雇了推特高管吗，那是他解雇前CEO帕拉格的时候。

[07:44 - 07:55] 所以它回答了所有这些问题，给出了所有这些链接，它就像一个很好的Slack机器人，我们都是后端和AI人员，所以我们没有时间构建前端，所以我们只是用Slack机器人进行测试。

[07:55 - 08:07] 然后当我们让它变得对话式、多人参与时，它开始变得有趣，其他人可以在别人问的基础上提问。

[08:07 - 08:15] 这里，尼克，我们的第一个工程师，他问，为什么埃隆要买推特，然后丹尼斯去问，他要私有化吗？

[08:15 - 08:30] 非常有用，你可以从看到其他人问的问题中学到很多东西，然后我们的投资者纳特·弗里德曼告诉我们，你知道，像Midjourney是一个Discord机器人，它不应该在Slack上工作，像Discord是下一个大事情。

[08:30 - 08:39] 所以你做一个Discord机器人，界面也比Slack好得多，所以我们做了一个Discord机器人，并且开始了一个小的Discord服务器。

[08:39 - 08:49] 这很有趣，娱乐性很强，无论谁加入服务器并尝试机器人，他们都会说，哦，这比谷歌好多了，我会每天使用它。

[08:49 - 08:59] 我们最初并不相信这一点，我们认为好吧，他们只是为了对我们友好和鼓励而这样说，但他们确实一直在使用它，所以给了我们很多，

[08:59 - 09:09] 你知道，希望这是真的。请注意，这仍然是我们在研究SQL企业产品的时候。所以这更像是一个干扰。

[09:09 - 09:24] 所以我不确定该怎么做，就像我们为什么要这样做，总是有这样的问题，但有一件事是真的，当某件事情开始起作用时，不断改进它会有一种多巴胺的感觉，当你看到人们要求的东西并且它，

[09:24 - 09:35] 你不断地发布并持续改进。你会感觉到势头。所以我的联合创始人，再次，丹尼斯，添加了这些焦点，你可以在维基百科上专门搜索。

[09:35 - 09:44] 然后你可以在Stack Overflow上专门搜索，它会回答我们所有的编码查询，比如这么多，好多。

[09:44 - 09:54] 所以这里有一些真正的东西，而这正是Chantipuri发布的前一天，你知道。

[09:54 - 10:05] 仍然不确定我们应该做什么，因为我们正在做其他事情，我们的公司应该做别的事情，我们看到了Chad GPT的发布，你知道现在如果想想的话，它是历史性的。

[10:05 - 10:16] 然后他们打破了几个神话，你需要在Discord上，人们不想聊天机器人，各种各样的事情，他们基本上打破了所有...

[10:16 - 10:32] 当时现有的智慧，所以我们非常受到鼓舞，并且认为我们仍然可以为他们发布的功能增加正交价值，因为我们有这种将实时知识和聊天机器人结合起来的编排。

[10:32 - 10:41] 所以这就像丹尼斯问尼克是否可以帮他解决CSS问题，因为我们不知道CSS。

[10:41 - 10:51] 然后，有趣的是，我试图用ChatGPT生成代码，然后它显然坏了。

[10:51 - 10:59] 所以然后尼克不知怎么地来帮助我们，然后我们把它发给了我们的友好投资者朋友之一，丹尼尔·格罗斯。

[10:59 - 11:11] 如果你看看他的第一个评论，你需要一个提交按钮，因为那是一个笑话，因为延迟太糟糕了，需要七秒或八秒才能得到答案。

[11:11 - 11:19] 而现在如果你使用我们的产品，几乎是即时的，这就是它经历了多少次迭代。

[11:19 - 11:30] 他给了我们很多好的反馈，这总是非常重要的，找到你的第一批喜欢你的产品的用户，然后我们有了这个完整的东西准备好了，我们要推出它，

[11:30 - 11:42] 然后我们有了勇气去推出它，纳特·费德曼说，去找一百个人，你知道，像一百个人来使用你的产品，所以我们推出了它，结果比预期好得多。

[11:42 - 11:54] 这就是当我们决定，好吧，我们有这个完整的SQL搜索为企业，我们在一些大型上进行了原型设计。

[11:54 - 12:04] 关系数据库。所以我们认为，像，我们不妨发布一些像公共数据库支持的SQL搜索，并测试哪个实际上有效。是Web搜索还是SQL搜索。

[12:04 - 12:19] 所以我们在Twitter上推出了搜索，这实际上让杰克·多西本人进来并给我们发推文说这很棒，这让更多人关注到困惑度，人们开始使用这两种产品。

[12:19 - 12:31] 我们跟踪了使用情况，我们看到常规的网络搜索产品得到了更多的使用，我们仍然不确定是否应该终止这个Twitter搜索，但埃隆让我们很容易做到这一点，

[12:31 - 12:44] 将API价格提高到除了谷歌以外没有人能再支付得起的程度，所以我们决定只专注于网络搜索，我们让它变得更好，我们让它完全端到端的对话式，

[12:44 - 12:53] 我们建议后续问题，然后像，你知道，我认为纳特很慷慨地说，

[12:53 - 13:02] 我们发货真的很快，这基本上是我们身份的一部分，有些人给我们的信用比我们应得的要多，但我认为...

[13:02 - 13:15] 这是我们与微软和谷歌竞争的唯一方式，他们都在尝试做所有这些相同的事情，所以我们一直在迭代，从一月份开始改进，尝试了许多实验。

[13:15 - 13:23] 然后下一个大的更新是推出这个叫做Copilot的东西，我们认为它像一个浏览伴侣，对吧？

[13:23 - 13:33] 它的工作方式是，直到现在，你只是问一个问题，AI插入到一个搜索索引中，得到答案。

[13:33 - 13:43] 并在直接的聊天机器人UI中给你。我们认为如果它更具有代理性并回到你身边会很酷。

[13:43 - 13:58] 问一些澄清的问题，然后给你答案，它生成的澄清问题是高度依赖于问题的，非常动态，它可以问的问题类型可以是多项选择或单项选择，

[13:58 - 14:13] 所以我们创新了这个叫做生成式UI的新东西，就像基于你的查询，根据它生成一个用户界面，而凡尔赛现在正在做伟大的工作，你知道的，试图根据你想要的东西生成网站。

[14:13 - 14:20] 所以我们在很久以前就有了这个想法，并且受到了当时围绕AutoGPT和baby AGI的所有噪音的启发。

[14:20 - 14:29] 但我们的论点是自主性还没有达到。我们仍然希望这些代理与我们一起工作。

[14:29 - 14:41] 所以我们设计了产品，这基本上成为了我们的，你知道的，专业计划的USP，人们使用专业计划就像副驾驶一样，为了更多，

[14:41 - 14:52] 研究类固醇，这是最好的思考方式，然后我们最近通过OpenAI的GBT 3.5微调API使其更快。

[14:52 - 15:04] 在左边，你可以看到运行副驾驶的微调GPT 3.5模型，在右边，你可以看到GPT四，所以GPT四会问你更多的问题，但是，

[15:04 - 15:17] 并不是所有的问题都是必要的，GPT 3.5要快得多，而且直接就到了核心点，所以我们理想中想要的是拥有GPT四的大脑并提出澄清问题的东西。

[15:17 - 15:27] 但在用户体验方面，GPD 3.5的速度和可靠性，这就是我们尝试用这个微调模型做的事情。

[15:27 - 15:37] 在指标方面，如果你只看我们的FTGPD 3.5是微调模型，而GPT四和三点五是原始模型。

[15:37 - 15:49] 八十％的时间用户无法说出哪个模型是哪个，八％他们认为微调模型更好，十一％他们认为GP四还是更好。

[15:49 - 15:59] 所以还有改进的空间。但这将更多地朝着，你知道的，用户无法说出的方向发展，对于Gpd来说。

[15:59 - 16:07] 像微调与原始GBT 3.5相比，你可以清楚地看到它比你知道的赢得更多。

[16:07 - 16:17] 没有微调。我们这样做是有原因的。这是因为你为输出标记支付的价格。

[16:17 - 16:29] 你知道，甚至不可比较，对吧，比如如果你看看输入标记，提示标记，你为GBT 3.5支付的费用比四低三倍，而对于输出标记，生成的标记，

[16:29 - 16:38] 你支付的费用低六倍，所以这说明我们每天服务的搜索请求量对我们有很大的影响。

[16:38 - 16:48] 而且在速度方面，你可以看到这里的吞吐量和延迟，就像白天和黑夜的区别，对吧？

[16:48 - 16:58] 所有这些都使得产品体验更好，比如当你在手机上使用糟糕的Wi-Fi或你在移动互联网上时。

[16:58 - 17:08] 这些事情很重要，所以我们考虑了很多，抓住了OpenAI有微调API可用的机会，并且更快地推出了这个功能。

[17:08 - 17:19] 其他人也对此表示赞赏，是的，这个人本人来了，他说这是一个很好的使用指标的例子，OpenAI的微调API。

[17:19 - 17:29] 是的，所以在产品中我们也支持其他研究用例，比如我们让人们上传文件，Cloud too也非常有用。

[17:29 - 17:40] 以它的长上下文和你知道的文件上传功能而受到赞赏和了解，所以我们不只是做文件上传，因为这样只是添加另一个功能会很酷。

[17:40 - 17:50] R 将成为任何人可以拥有的最好的研究助手，并且上传你的文件并询问有关它的问题就像任何研究工作流程中的一个非常重要的组成部分。

[17:50 - 17:59] 所以我们只是做了这个，我们认为云二在这方面比GPT四有更强的能力。

[17:59 - 18:06] 因此，我们与Anthropik合作，使这成为可能，这也为我们赢得了大量的积极关注。

[18:06 - 18:16] 最近，我们推出了这个叫做Collections的东西，这是我们从仅仅是一个工具到端到端平台的转变。

[18:16 - 18:24] 在这里，你可以，而不是只是在某个地方粘贴我们的URL并在你的Slack或WhatsApp上分散开来，或者像。

[18:24 - 18:40] 在你的电子邮件中，我们只是认为如果所有这些都像持久的并且保存在某个地方，你可以与人合作，你也可以拥有自己的隐私级别，关于你想公开分享什么和保持私密。

[18:40 - 18:50] 所以如果你想有一套集合来规划你的假期旅行与你的朋友或家人，那么这与另一套集合不同，在那里，

[18:50 - 19:00] 你正在对公司的研究，或者你有一些关于你正在学习的新框架的编码查询。所有这些都可以像，你知道，解耦，对吧。

[19:00 - 19:09] 所以这更像是一个平台，而不仅仅是一个工具，这是非常重要的，因为我们认为这是一种真正区分自己的方式。

[19:09 - 19:18] 让人们每天回来使用产品。所以这是我们在未来几个月里会做的更多的一件事。

[19:18 - 19:25] 这个东西我想，你知道，我之前说过，有很多关于，你知道。

[19:25 - 19:36] 不同的意见，关于是rapper还是训练你自己的模型，哪个更受尊重，或者创业公司需要什么。

[19:36 - 19:50] 这部史蒂夫·乔布斯电影中有这段代码，沃兹尼亚克基本上问他，你到底做什么，你不做硬核工程，他说，我指挥乐团。

[19:50 - 19:59] 指挥，就像指挥不同的组件，搜索索引，LLM，对话。

[19:59 - 20:09] 渲染答案，多模态，这并不容易，即使在做一个rapper，如果你决定要做一个rapper，你最好成为一个好的rapper，对吧？

[20:09 - 20:18] 然后魔鬼就在细节中。例如，我在推特上讲了Bard扩展的故事。

[20:18 - 20:26] 我尝试了一下，嘿，我只是看看这是否有效，也许我对编排的看法是错的，然后我只问他们在过去两个月里乘坐了多少次航班。

[20:26 - 20:39] 它甚至没有插入我的Gmail来给我答案，然后有一个用户在这里回复我说，当处理文档时，困惑度给出了更好的答案。

[20:39 - 20:50] 没有幻觉，然后同样这也是另一个叫做UChat的产品，然后我甚至不喜欢试图欺骗它，我只选择他们建议的查询。

[20:50 - 20:59] 写一首关于海洋中鲸鱼的歌，然后它给我一个天气拒绝，就像我没有问天气一样，对吧？

[20:59 - 21:11] 很容易说，哦，是的，我们连接了所有这些插件，我们连接了所有这些API、数据提供商，然后当你尝试时，它在推理时间做了一些不可靠的事情。

[21:11 - 21:20] 所以这就是为什么我们在这里更加小心，并试图用思考来做这件事，比如斯坦福大学评估。

[21:20 - 21:30] 所有这些生成式搜索引擎，你有两个轴在这里，一个是感知效用，另一个是引用F1分数。

[21:30 - 21:41] FN分数只是精确度和召回率的加权平均值，你希望在这两个方面都做得好，也就是说，你想要有一个高的引用分数，这样，

[21:41 - 21:51] 你可以用相关的链接来支持你在答案中所说的话，你也希望有高的效用分数，这样你的答案对用户来说是可读的，并且能带来良好的体验。

[21:52 - 22:04] 因此，你希望尽可能地在右上角，并且不要太偏向于Y轴或X轴，你看，我们是四个中最好的部分。

[22:04 - 22:13] 在这篇论文发表的时候，当时我们只使用GPD 3.5，而Bing默认使用GPD四。

[22:13 - 22:21] 如果我们用当前的模型重新进行评估，这个模型要好得多，我相信我们在这些指标上的得分会更好。

[22:21 - 22:31] 人们看到了这一点，现在人们在推特上谈论它，在我们筹集资金的时候。

[22:31 - 22:39] 正是Bing推出的时刻，我们自己有很多恐惧，更不用说周围的人吓唬我们了。

[22:39 - 22:55] 像为什么你要在微软会赢的地方工作，但我认为我们在过去几个月中学到的是，这不仅仅是一次发布，你必须不断迭代和改进，最终用户会意识到更好的产品。

[22:55 - 23:05] 所以即使现在也不是像，哦，你不需要像这个人那样思考他已经领先了，但是你知道，我们完全理解，我们必须不断改进产品。

[23:05 - 23:15] 但最重要的是建立平台、飞轮、基础设施和迭代组件，这是我们迄今为止非常高兴做的事情。

[23:16 - 23:29] 这是对如何最好地解释R2的一个很好的总结，基本上就像维基百科和Chanche Piti有了一个孩子，但数据不仅仅是维基百科，它是来自整个互联网。

[23:29 - 23:37] 所以它是深入研究任何主题的完美工具，它是为像你这样的人设计的，我们都像...

[23:37 - 23:47] 我们有兴趣深入挖掘并探索兔子洞，所以这是想法，它应该激发像你这样的人使用这些产品。

[23:47 - 23:55] 另外，我们也收到了这样的反馈，我们不想仅仅成为一个说唱歌手。

[23:55 - 24:04] 所以我们也在尝试提供我们自己的模型，并以此为目标，我们首先推出了Lama模型作为困惑实验室的一部分。

[24:04 - 24:14] 它是目前最快的推理Lama，比其他产品如hugging face复制还要快。

[24:14 - 24:24] 许多人也在提供Lama模型，但在指标方面，我们发布了我们的指标，你实际上可以看到每秒的标记数，第一个标记的时间。

[24:24 - 24:33] 所有这些，对吧，所以我们有最好的延迟，我认为这个人也评估了它。

[24:33 - 24:46] 还有这么多人，意识到我们运作得最好，所以实际上我想做一个模型的演示，我们今天刚刚在困惑实验室推出，

[24:46 - 24:56] 它叫做Lama 213B SFT，所以这是我们在训练自己的模型方面迈出的一步，而不仅仅是提供Meta的模型。

[24:56 - 25:04] 如果你记得的话，Lama因为有...

[25:04 - 25:12] 基本上使用起来非常烦人，它只是不听从我们的指示。

[25:12 - 25:21] 它太安全了，对吧，然后我们决定，好吧，这是一个很好的微调步骤，你知道，如果你回到。

[25:21 - 25:27] 原始的Lama。并要求它做同样的事情。它不会回答你。所有这些东西。

[25:27 - 25:32] 所以如果你问它如何杀死Linux进程。

[25:32 - 25:42] 它只会告诉你我被编程为确保人们的安全和福祉，我不能告诉你怎么做，所有这些事情，或者它不会给你，

[25:42 - 25:52] 你想要的笑话，或者关于任何人的笑话，我们决定至少尝试微调这些模型，使其更有用而不是。

[25:52 - 25:59] 走向无害的方向，所以这是我们正在尝试的一个实验，并且。

[25:59 - 26:09] 我们希望更多地更新人们关于我们自己的模型的信息，并开始通过产品提供我们自己的模型。所以现在，在困惑中。

[26:09 - 26:17] 你已经得到了这个，你知道，如果你在专业计划上，你可以选择你喜欢的模型，比如我们有自己的模型，那是GPT四，那是CLOT二。

[26:17 - 26:29] 我认为随着时间的推移，我们提供的模型将最适合这个特定的产品，我们也希望人们不要...

[26:29 - 26:37] 人们可能不会足够关心去选择他们喜欢的模型，而是有一个只工作的模型。

[26:37 - 26:42] 这就是我们的目标，这就是为什么我们尝试所有这些实验来训练和提供我们自己的模型。

[26:43 - 26:51] 是的，所以基本上就是这样，我想我有一些时间可以回答问题。

[27:01 - 27:06] 是的。

[27:07 - 27:14] 那么你在这里使用ray的地方在哪里，ray的使用在哪里？

[27:14 - 27:24] 你在使用Ray吗，Ray的任何部分用于训练或...是的，所以我们考虑将其用于微调模型。

[27:24 - 27:34] 我们目前正在测试基于Megatron和任意规模微调的我们自己的基础设施。

[27:34 - 27:42] 所以我们很快就会在这方面有所说法，目前还没有生产环境中的东西，也没有我们可以公开宣布的东西。

[27:42 - 27:52] 好的，谢谢，还有引用，对吧，你指出了那篇论文，我是你们两个的用户，u.com和Perplexity。

[27:52 - 28:05] 所以它们也在改进，我现在看到两者都是平等的，那么你应对这种竞争的路线图是什么，现在两者都是平等的，因为是在同一个数据集上，因为我是一个斯坦福的学生。

[28:05 - 28:15] 然后相同的。现在两者都是平等的。那么你的路线图是什么？我的意思是，你可以与我们分享你的结果。我不认为两者是平等的，但如果这是真的，那么我们会。

[28:15 - 28:20] 我可以对此发表更多的评论，当然，当然，谢谢你。

[28:24 - 28:29] 第一。

[28:32 - 28:43] 嗨，我一直都在使用困惑。感谢你构建它。我经常注意到当我问一个问题时，困惑上出现的引用。

[28:43 - 28:52] 比我在谷歌上找到的要好得多。谷歌仍然在对SEO文章进行大量排名，因为您仍在搜索互联网，找到这些数据点。

[28:52 - 29:04] 您是如何保持所使用的链接的真实性的？是的，所以我们有自己的网页排名，并且我们也有LLMs非常擅长，

[29:04 - 29:15] 选择正确的相关链接，所以LLMs选择引用哪些论文、哪些链接的最终组成部分。

[29:15 - 29:21] 实际上是一个很大的相关性排名提升，所以这也很有用。

[29:21 - 29:31] 谢谢 是的，我有一个问题，为了使Lama运行得这么快，你不得不做出什么权衡，因为它看起来相当快。

[29:31 - 29:41] 是的，所以我们基本上有自己的自定义推理堆栈，你知道，我们显然会看所有的东西。

[29:41 - 29:49] 帮助其他人，比如闪存注意力或使用facet变压器，页面检测，所有这些不同的想法。

[29:49 - 30:00] 但我们决定使用自己的堆栈，而不是依赖于hugging face或像VLLM，因为这样我们可以控制更多。

[30:00 - 30:12] 是的，所以我会说，在某个时候，你必须去写一些Cura级别的东西，对吧？

[30:12 - 30:16] 否则，很难让事情变得更快。

[30:25 - 30:42] 我认为你谈到了你正在定制自己的模型，从更大的空间背景来看，你是如何看待开源的作用的，你是否想象你会越来越多地走这条路，远离chatGPT，或者你仍然会使用云或chatGPT？

[30:42 - 30:50] 是的，我认为GPD 3.5微调和开源之间存在竞争。

[30:50 - 31:01] 模型，对吧，就像当我们认为好吧，Lama很棒，我们宁愿只是微调Lama，然后OpenAI也宣布了GBT 3.5微调。

[31:01 - 31:10] 因此，如果我们目标只是为了使产品更好，我们会做短期内更便宜、更容易做的事情。

[31:10 - 31:18] 话虽如此，我还是认为有些事情没有访问权重就无法做到。

[31:18 - 31:26] 可能其中一些只是响应的风格。

[31:26 - 31:35] 如果你想让LLMs更具可定制性，更具代理性，所有这些东西，我认为拥有自己的模型是有帮助的。

[31:35 - 31:45] 此外，你无法控制价格，对吧，这是最重要的部分，撇开技术不谈，只从商业角度来看。

[31:45 - 31:52] 就像如果你不能控制某物的价格，它总是处于一个棘手的位置。

[31:52 - 32:02] 这些API的价格是否会一直保持今天的样子，还是会上升或下降还不清楚。

[32:02 - 32:06] 所以对你来说，拥有自己的东西是好的。

[32:08 - 32:16] 我认为到明年年中，它肯定会赶上GPT四。

[32:16 - 32:22] 但等到他们推出GPT-5的时候，可能会有一些延迟，我想。

[32:22 - 32:30] 对不起，我们没能回答所有的问题，但让我们再给Arvind一次掌声。

