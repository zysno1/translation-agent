# Ray at Scale: Apple's Approach to Elastic GPU Management | Ray Summit 2024

## 视频信息
- 视频ID: ZCRZQVt-r3g
- 视频标题: Ray at Scale: Apple's Approach to Elastic GPU Management | Ray Summit 2024
- 视频URL: https://www.youtube.com/watch?v=ZCRZQVt-r3g

## 译文
[00:05 - 00:06] 大家好。

[00:06 - 00:08] 感谢大家，欢迎来到我们的演讲。

[00:08 - 00:20] 今天峰会的倒数第二场演讲，我和韦伟将为大家介绍弹性GPU管理在Ray中的应用，以及如何实现对AI工作负载的可扩展性和效率提升。

[00:22 - 00:24] 首先，我们来看一下介绍幻灯片。

[00:24 - 00:30] 我曾在苹果公司和Linton公司与Ray社区合作过。

[00:30 - 00:34] 然后，韦伟，你能不能介绍一下你自己？

[00:34 - 00:34] 当然可以。

[00:34 - 00:35] 大家好。

[00:35 - 00:49] 我是韦伟，目前在苹果公司的数据和基础设施团队工作，主要帮助团队构建在多个云上运行数据处理和机器学习工作负载的基础设施。

[00:53 - 00:59] 今天我们将为大家简要介绍Ray。

[00:59 - 01:11] 我们将讨论GPU工作负载的扩展挑战，以及我们在优化GPU容量管理和利用率方面尝试的一些技术。

[01:12 - 01:14] 为什么要使用Ray呢？

[01:14 - 01:23] Ray为数据处理、训练、调优和服务提供了一个统一的计算API。

[01:23 - 01:35] 对于我们来说，它的一个优点是提供了这种无缝的API，可以在用户的笔记本电脑到数据中心之间工作。

[01:35 - 01:44] 用户可以尝试一些小实验，然后在不进行太多更改的情况下将其迁移到集群中。

[01:45 - 01:50] 它对模型服务有很好的支持，包括VM。

[01:51 - 01:55] 用户以三种不同的方式使用我们的Ray平台。

[01:55 - 01:59] 笔记本用于早期迭代。

[01:59 - 02:03] 这是他们可以尝试早期实验的地方。

[02:03 - 02:06] 他们可以像在自己的笔记本电脑上一样尝试。

[02:06 - 02:15] 这是一种交互模式，然后他们可以使用相同的API在数据中心进行全规模、大规模的工作负载。

[02:15 - 02:24] 此外，用户总是需要成熟的SDK来进行程序化的作业提交和模型部署。

[02:24 - 02:36] 还有门户来支持基于UX的模型部署和可观测性，这是任何生产化工作负载中非常重要的一部分。

[02:37 - 02:45] 尽管Ray有许多功能，但在使用过程中也存在不少挑战。其中之一就是资源分配。

[02:45 - 02:51] 当涉及到用户可以请求的资源类型时，选项太多了。

[02:51 - 03:02] 这并不是ML从业者在执行批处理推理作业或部署模型时首先考虑的问题。

[03:02 - 03:09] 自动缩放试图帮助解决这个问题，但也带来了我们所看到的自身挑战。

[03:09 - 03:25] 最后，GPU利用率是一个问题，无论是ML从业者还是基础设施工程师都在努力解决，因为对GPU的需求很高，而且涉及的成本也很高。

[03:26 - 04:18] 更深入地探讨这个问题，用户在选择不同的基础设施资源时，他们必须根据节点上的卡数量、GPU内存、SRAM与DRAM、GPU内部连接、特定地理区域的网络拥塞、区域的整体容量和拥塞等因素来选择节点或机器。这些选择对于人类来说太难指定了，尤其是在他们启动相当大的工作负载或在模型部署中进行生产化时。

[04:18 - 04:32] 所以我们的观察是，减少选择并提供某种标准计算选项是有帮助的。

[04:32 - 04:43] 想想小、中、大，并且提供用户可以交流的抽象，然后他们可以选择。

[04:43 - 04:45] 好吧，我需要这个。

[04:45 - 04:55] 然后我们的平台根据用户的选择提供特定的资源配置。

[04:55 - 05:01] 虽然这并不能优化所有情况，但它覆盖了我们80%的情况。

[05:01 - 05:20] 我们在寻找如何优化GPU使用案例以及如何允许用户提供他们需要的正确类型的节点或机器的过程中采取了一个中间步骤。

[05:20 - 05:22] 这并没有很好地工作。

[05:22 - 05:38] 因此，我们无法为用户提供这些选择，最终导致了更多的碎片化和比以前更低的利用率。

[05:38 - 05:45] 所以我们从那个方向退了出来，然后开始研究多级调度。

[05:45 - 06:02] 在节点级别调度可以处理多种类型的节点和实例，并且可以在主要用户请求不可用时回退到不同的选项。

[06:05 - 06:20] 另一个重要的优化GPU利用率的部分是支持自动扩展，因为大型工作负载的资源利用率，无论是批处理还是实时处理，都不会保持静态。

[06:20 - 06:25] 它会随着工作负载的生命周期而变化。

[06:25 - 06:34] 我们在峰会早期听到，来自Meta的Serge谈到了Llama在训练期间需要增加其批处理大小。

[06:34 - 06:38] 我们也观察到了类似的事情。

[06:38 - 06:47] 幸运的是，Ray对批处理和实时工作负载都有原生的自动扩展支持。

[06:47 - 06:54] Ray的自动扩展器的工作方式很棒。

[06:54 - 07:07] Ray的自动扩展器的工作方式是，它会监视工人的指标，并基于此修改CRD。

[07:07 - 07:09] 然后我们有这个。

[07:09 - 07:25] 我们使用Apache Unicorn，它会监视Ray自动扩展器所做的修改，然后根据自动扩展器的额外需求来排队Pod和工作负载。

[07:25 - 07:35] 然后它在降级方面做同样的事情，并尝试协调和影响打包工作负载。

[07:37 - 07:47] 然而，尽管有成功的自动扩展，但随之而来的一些挑战。

[07:47 - 08:02] 首先，对于非常大的工作负载，我们想要做出选择，我们是否希望受到地理区域的限制，或者我们是否希望跨越地理区域。

[08:02 - 08:09] 但是，如果我们想要跨越区域，那么就需要考虑数据传输成本。

[08:09 - 08:21] 然后出现的下一个问题是，即使在单个区域内，工作负载可能在升级时没问题，但在许多工作负载中，降级是不被接受的。

[08:21 - 08:31] 这就是我们在很多有状态的工作负载中看到的，降级会导致失败。

[08:31 - 08:40] 因此，为了防止这种情况发生，我们需要确保，好吧，工作负载，我们的Ray工人不能被驱逐。

[08:40 - 08:45] 所以它们可以被升级，但不能被降级。

[08:45 - 08:55] 这导致了利用率的降低，因为我们创建了一种无法缩小的工作负载。

[08:55 - 09:02] 因此，为了解决这个问题，我们更加关注检查点。

[09:02 - 09:17] 但是为了支持更好的检查点，我们必须从一个用户可以轻松使用的平台引入更好的API，以便在所有不同的用例中进行标准检查点。

[09:17 - 09:25] 当我们解决了这个问题后，下一个问题就是快速扩展。

[09:25 - 09:39] 首先，快速向上扩展会带来自己的问题，节点初始化开始出现不同的问题，比如表面和证书管理可能还没有准备好。

[09:39 - 09:45] 节点还没有完全准备好，IP地址可用性也没有完全到位。

[09:45 - 09:55] 所有这些问题都在自动缩放变得广泛可用并且用户可以快速向上自动缩放时开始显现出来。

[09:55 - 10:12] 为了解决这个问题，我们必须努力保持余量，以确保始终有额外的节点可用，这与利用率存在权衡。

[10:12 - 10:20] 没有调度器的支持，这些步骤都不可能实现。

[10:20 - 10:24] 现在深入探讨一下由weway提供的调度器。

[10:24 - 10:25] 谢谢。

[10:25 - 10:25] Bin。

[10:25 - 10:33] 我将谈论GPU管理和GPU资源抢占，这是我们大量使用的东西。

[10:33 - 10:49] 我认为在apppoo的用例中，我们有很多组织、团队想要使用ray，如何真正地将有限的GPU提供给所有这些团队、组织。

[10:49 - 10:55] 这是我们想要解决的关键问题，也是我们选择approunicorn的原因。

[10:55 - 10:59] 所以，aperture unicorn是一个Kubernetes资源计算器。

[10:59 - 11:05] 因为我们运行reon Kubernetes时，确实看到了很多挑战。

[11:05 - 11:17] 其中最重要的是我们看到的资源碎片化，不同的GPU节点没有被充分利用，因为这种碎片化无处不在。

[11:17 - 11:20] 同时，管理GPU配额也非常困难。

[11:20 - 11:30] 想象一下，你有很多不同类型的实例，并且你想把这些实例与不同的团队共享，这非常难以管理。

[11:30 - 11:33] 不同类型GPU的配额。

[11:33 - 11:37] 同时，GPU利用率也是一个问题，它总是成为一个问题。

[11:37 - 11:45] 我们知道人们抱怨没有得到足够的GPU，但有时实际上有时GPU是空闲的。

[11:45 - 11:47] 我们不希望这种情况发生。

[11:47 - 11:50] 同时，缺乏可观察性。

[11:50 - 11:55] 我认为这是很多地方都缺失的东西。

[11:55 - 11:57] 我们正在努力把它做得很好。

[11:57 - 12:01] 所以，uunicorn实际上帮助我们解决了许多问题。

[12:01 - 12:06] 它具有基础设施和资源的复杂性，来自ray。

[12:06 - 12:14] 所以让读专注于应用程序方面的事情，而uniicorn处理底层的资源管理和调度。

[12:14 - 12:24] 对于我们来说，这真的把多租户的rally平台带给了我们的最终用户，并且在过程中提供了巨大的成本节省。

[12:25 - 12:28] 只是关于独角兽的一个快速回顾。

[12:28 - 12:40] 它是Kubernetes上的资源调度器，它提供了很多调度能力，并提供了很高的效率和改进的SRA。

[12:40 - 13:05] 关于独角兽提供的一些功能亮点，例如资源队列，这对于多租户至关重要，并且在不同的队列之间提供了资源公平性，还提供了枪支调度，这对机器学习工作负载非常重要，还有非常复杂的资源比例。

[13:05 - 13:08] 我会在稍后的会议中详细解释。

[13:08 - 13:12] 我们大量使用它并与独角兽集成。

[13:12 - 13:27] 好消息是，在过去的两个月里，独角兽社区与上游合作，将独角兽集成贡献给上游，很快就会在下一个版本中可用。

[13:27 - 13:42] 有了这个集成，为Forray启用独角兽非常简单，你只需要设置一个标志，批量调度器，设置一个名为独角兽的名字，你已经安装了独角兽，然后你可以轻松地使用所有这些独角兽。

[13:42 - 13:47] 使用它的方法基本上是你可以设置标签，非常简单的标签。

[13:47 - 13:56] 可能一个是应用程序ID，另一个是Q名称，以告诉独角兽你想在哪个队列上运行你的recuster rejob。

[13:56 - 13:58] 然后它会开箱即用。

[13:58 - 14:00] 所以只是一个快速的例子。

[14:00 - 14:07] 你更喜欢读取作业回来，你给那个标签来定义这个应用程序的应用程序ID是什么。

[14:07 - 14:10] 你定义你想提交这个作业到哪个Q。

[14:10 - 14:20] 然后一旦你将规范提交到QA，q buoperator将基本上创建一个Q bernejob和一个带有头端工作者的reccluster。

[14:20 - 14:38] 因为集成已经完成，所以独角兽基本上可以看到这些工作者和头部是从这个应用程序来的，他们会将集群放入我们管理GPU资源的队列中，并将应用。

[14:38 - 14:43] 所有那些策略都称为我们在位的策略，用于这个工作负载。

[14:44 - 15:06] 当你运行rejob或recclustering cues时，它将与在本机cobernetes中的命名空间中运行非常不同，因为每个队列都提供了关于资源配额的良好概念，并且提供了关于保证和最大配额的概念在两个维度上。

[15:06 - 15:09] 这样真的使这些队列具有弹性。

[15:09 - 15:15] 当我们有不同的recclusters在队列中运行时，它支持优先级。

[15:15 - 15:25] 它还支持五种排序和其他策略，以便对应用程序进行排序而不是队列，以确保正确的应用程序首先获得GPU。

[15:25 - 15:37] 而且在这些队列之间，我们正在做资源公平性，这是极其重要的，因为我们有很多情况下人们都在争夺GPS。

[15:37 - 15:49] 我们不想让任何人不高兴，但我们只是想在那里保持一个公平的政策，以确保每个团队仍然可以在我们的系统高峰时段获得一些GPU来使用。

[15:49 - 15:52] 在底层是一个大型共享GPU池。

[15:52 - 16:03] 我们在这里试图得到的原则基本上是我们希望确保GPU池尽可能多地被所有这些团队共享。

[16:03 - 16:18] 在某些情况下，我们仍然像在某些极端情况下一样进行隔离，但在大多数情况下，我们希望使用一个大型GPU来分享给每个人，并使用独角兽来管理所有那些GPU配额，这工作得很好，很快。

[16:18 - 16:25] 这里是一张幻灯片，介绍我们在ray中使用的unicorn的功能。

[16:25 - 16:32] 第一个是GPU配额管理，它可以管理许多不同的资源类型。

[16:32 - 16:33] GPU是其中之一。

[16:33 - 16:37] 第二个是超额订阅。

[16:37 - 16:52] 我认为这是关键，我们能够超额订阅我们的队列，以利用更多的空闲GPU，这样我们就可以在GPU集群下放置大量的共享队列，将集群利用率提高到非常高的水平。

[16:52 - 17:01] 队列层次结构是我们认为对于复杂的组织结构很有意义的东西。

[17:01 - 17:31] 因此，我们可以使用它来映射组织结构，确保我们对不同层次的组织进行适当的管理，从一个大型业务线到小团队或个人，以及资源公平性，这是我们实际使用的东西，默认情况下适用于所有GPU，并保证最大容量是关键，我们可以为客户提供不同级别的GPU。

[17:31 - 17:35] 例如，保证是您始终可用的一些GPU。

[17:35 - 17:38] 最大是最大的努力。

[17:38 - 17:43] 节点打包是我们真正确保节点被充分利用的机制。

[17:43 - 17:52] 节点打包有两个部分，稍后会详细讨论，但这是关键，我们如何真正充分利用节点资源。

[17:52 - 18:00] 队列是队列在你耗尽容量时根本提供的东西。

[18:00 - 18:10] 我们不会拒绝你的应用程序，只是在队列中等待，直到有人释放GPU，同时也支持优先级。

[18:10 - 18:16] 因此，我们确保我们在调度和抢占方面都考虑了优先级。

[18:16 - 18:18] 最后是抢占。

[18:18 - 18:27] 我们大量使用它来确保我们超卖CPU，但同时当我们需要它们回来时，我们有适当的方式来收回GPU。

[18:28 - 18:31] 这是一个非常简单的例子。

[18:31 - 18:35] 右边是示例配置。

[18:35 - 18:36] 你可以很容易地配置。

[18:36 - 18:42] 你可以设置几个具有保证的最大GPU配额的队列。

[18:42 - 18:54] 这些队列还提供了一些额外的功能，例如你可以根据需要配置动态队列或静态队列，以及支持队列层次结构。

[18:54 - 18:55] 还有ACS。

[18:55 - 19:17] 有趣的部分是，我们正在朝着管理多种类型的GPU的方向发展，在过去这对我们来说是非常困难的，因为即使我们有混合多样化的GPU实例类型，GPU中使用的资源仍然是单一类型的。

[19:17 - 19:30] 对于我们来说，这不是很方便，因为在某些情况下，一些高性能的GPU，我们希望限制团队的使用，并希望他们尽可能使用更便宜的实例。

[19:30 - 19:35] 所以我们没有一个好的方法来管理不同类型的GPU。

[19:35 - 19:42] 我们正在探索一种使用修改过的GPU驱动程序来暴露不同类型的GPU资源的方法。

[19:42 - 19:45] 然后你可以通过unicorn真正地进行管理。

[19:45 - 19:55] 然后我们有一个更少的图表，这是来自Metrix的关于每个队列的保证GPU、最大GPU和当前利用率的图表。

[19:55 - 19:59] 这样我们就可以轻松跟踪不同类型GPU的分布。

[19:59 - 20:01] 你想联系他们吗？

[20:01 - 20:03] 您是否要更改布局？

[20:03 - 20:05] 所以这完全取决于我们。

[20:05 - 20:06] 所以这非常方便。

[20:06 - 20:09] 这是我们正在探索的东西。

[20:10 - 20:22] 因此，如上所述，这是我们要解决GPU碎片化问题的关键功能之一，这是一个真正严重的问题。

[20:22 - 20:33] 我们经常看到集群利用率很高，但GPU工作者无法获得GPU，因为每个节点上的空间都不够。

[20:33 - 20:37] 只是因为这里和那里有碎片。

[20:37 - 20:40] 不，我们在浪费我们的GPU时间。

[20:40 - 20:42] 因此，我们有两个打包。

[20:42 - 20:47] 一个是使用独角兽提供的调度阶段打包。

[20:47 - 21:03] 这是一个你可以控制的策略，它基本上会在每个部分分配的调度期间，尝试找出，尝试打包更多的部分，增加节点上的密度，确保节点在移动到下一个节点之前被充分利用。

[21:03 - 21:18] 所以这是一个调度阶段，但这并不能解决所有问题，因为一段时间后，你会说碎片化问题再次出现，然后我们需要一些后调度打包机制。

[21:18 - 21:38] 目前我们正在使用木匠来做这件事，它基本上会扫描你集群上的pouh分布，并尝试移动周围的垫子，使其更具影响力，这样我们就可以冻结一些节点，要么缩小规模，要么为更大的工作留下空间，你知道更大的GPU请求。

[21:38 - 21:43] 使用这个工具，我们可以大大减少碎片化。

[21:44 - 21:47] 而枪支调度是一个非常重要的功能。

[21:47 - 22:05] 这些也成为了上游q提供的与独角兽集成的功能，非常简单，你只需要在你的cr tauh上贴一个私人标签，启用枪支调度，然后它会给独角兽调度员一个提示。

[22:05 - 22:09] 所以我想为这个应用程序启用枪支调度。

[22:09 - 22:13] 这是你可以应用的每个应用程序的配置。

[22:13 - 22:22] 一旦你启用了它，独角兽会做什么，基本上是在实际调度之前提前保留所有资源。

[22:22 - 22:33] 这样我们就可以真正避免某些集群只得到部分资源，而没有一个工作者在工作，取得进展的情况。

[22:33 - 22:35] 是的，这很有帮助。

[22:36 - 22:41] 然后我会花一些时间来谈谈GPU权限。

[22:41 - 22:47] 这是我们最近用来提高利用率的一个相当新的功能。

[22:47 - 23:00] 因为我们支持这么多不同的用例，那里有延迟敏感或非敏感的工作负载，交互式会话，实时会话，还有一些快速装饰实验。

[23:00 - 23:04] 用户只是想尽快得到结果。

[23:04 - 23:13] 所以在所有这些不同的用例中，用户只是想要非常简单，只是想在x yz小时内完成他们的工作。

[23:13 - 23:14] 有道理。

[23:14 - 23:22] 但是另一方面，管理员真的想让集群利用率高，GPU太贵了。

[23:22 - 23:25] 我们不想在那里浪费很多钱。

[23:25 - 23:27] 所以有一个冲突。

[23:27 - 23:32] 我们如何解决这个问题，我们利用独特的保证最大容量。

[23:32 - 23:40] 它的意思是什么？基本上我们可以为每个队列定义保证容量。

[23:40 - 23:45] 这个就是调度器在任何情况下都会满足的容量。

[23:45 - 23:51] 即使每个队列都在竞争GPU，那些保证的容量仍然可用。

[23:51 - 23:54] 而这个最大值就是你可以扩展你的队列的方式。

[23:54 - 23:59] 如果其他团队没有使用GPU，集群上会有一些可用的GPU。

[23:59 - 24:03] 那些GPU将最多达到你的最大值。

[24:03 - 24:11] 这样我们就可以在一个集群中放入很多队列，根据客户的需求保证一个最大容量。

[24:11 - 24:14] 然后我们能够使它们真正具有弹性。

[24:14 - 24:21] 在空闲时间，我们确保利用率，因为某些队列仍然有未完成的请求。

[24:21 - 24:27] 但在繁忙时段，我们会进行抢占以确保保证仍然可以满足。

[24:28 - 24:33] 我将快速演示一下这是如何工作的。

[24:33 - 24:38] 想象我们有两个队列，非常简单，两个队列现在，集群是空的，队列也是空的。

[24:38 - 24:41] 利用率都是零。

[24:41 - 24:44] 所以现在让我们看看，我们有一些工作负载。

[24:44 - 24:49] 第一个队列中的recclusters正在运行，它使用了30%。

[24:49 - 24:53] 所以两个队列都是，我们将最大值设置为集群的最大值。

[24:53 - 25:03] 但作为第一个队列，我们给了60%的保证GPU，而第二个队列只得到了40%，40%，20%，40%。

[25:03 - 25:16] 然后一旦我们提交了recclusters到第一个队列，它就开始消耗资源，现在我们，是因为第二个队列中没有工作负载，它消耗了50%的GPU。

[25:16 - 25:17] 这很好。

[25:17 - 25:24] 我们甚至可以更高，因为这个队列真的很忙，我们将其扩展到100%。

[25:24 - 25:25] 这很好。

[25:25 - 25:45] 我们很高兴，因为现在所有的GPU都被利用了，但是如果有一个另一个reccluster被提交到第二个队列，现在集群中没有可用的GPU，依赖于这些GPU的部分数据集，这次独角兽基本上开始触发抢占过程。

[25:45 - 25:56] 因为现在发生的是第一个队列使用的超过保证容量，但第二个队列需要一些更多的资源来达到保证容量。

[25:56 - 26:07] 所以独角兽基本上会说，哦，我需要从过度使用的队列中移动一些vGPU到未充分利用的队列，并且它基本上会尊重保证容量。

[26:07 - 26:16] 当你做抢占时，你也会考虑应用程序优先级和任务优先级以及你的任务运行了多长时间。

[26:16 - 26:23] 想象如果任务部分相同，那么你基本上会选择两个pales来打印一个非常简单的例子。

[26:23 - 26:27] 然后你会收回GPU并重新分配GPU到第二个队列。

[26:27 - 26:31] 然后第二个队列将获得资源来运行。

[26:31 - 26:39] 但是想象如果你在这个时候，如果你提交更多工作负载到第二个队列，因为我们仍然在100%利用率以下。

[26:39 - 26:43] 所以第二个队列将无法获得GPU使用。

[26:43 - 26:46] 这是我们给用户的合同。

[26:46 - 26:51] 我发现这对我们用户来说很容易理解它是如何工作的。

[26:51 - 26:59] 他们能够提出一些关于他们如何在他们的保证容量上操作的设计。

[26:59 - 27:01] 对我们来说效果很好。

[27:01 - 27:06] 这里是一个模拟，只是为了模仿它是如何工作的。

[27:06 - 27:18] 因为我们有这些关于跟踪不同队列利用率的指标，我们能够可视化地看到它是如何工作的。

[27:18 - 27:22] 这是一个非常常见的生产用例。

[27:22 - 27:30] 例如，当我们启动集群时，我们启动了五个队列，其中一个队列的工作负载比其他队列多得多。

[27:30 - 27:35] 这是非常常见的，我们让它使用更多的资源。

[27:35 - 27:41] 如你所说，大多数GPU都被第一个队列所利用，这是好的。

[27:41 - 27:56] 那么如果其他队列也开始请求GPU呢？因为所有的GPU都在被使用，那么我们会考虑确保每个队列仍然可以获得保证的容量。

[27:56 - 28:06] 如果你看那个时刻，抢占开始将GPU从第一个队列重新分配到其他队列。

[28:06 - 28:11] 如果你比较这两个图表，第一个队列使用了400多个GPU。

[28:11 - 28:20] 但经过一段时间后，所有队列都将准确地获得之前定义的保证容量。

[28:20 - 28:29] 所以这就是我们在生产中如何工作的，只是为了给每个团队提供保证的容量和最大容量。

[28:29 - 28:36] 我们设法为保护集群做到这一点，并且工作得很好。

[28:39 - 28:42] 所以关于这个会议的快速总结。

[28:42 - 29:05] 我们在苹果公司扩展Ray时遇到了很多问题，我想我们希望你们从这个会议中带走的是，首先非正式的集群是多租户环境所需要的，而且可靠的自动扩展是效率的关键。

[29:05 - 29:24] 有很多不同的挑战，就像被提到的那样，使我们的扩展真正可靠，而且我们也尝试使用多样化的循环池，我们正在尽可能多地使用多样化的循环池。

[29:24 - 29:58] 只是为了确保我们的所有队列可以非常容易地访问不同类型的GPU，而且也使用打包来减少调度阶段和调度后的碎片化，并且还利用独角兽队列进行多租户，如何为每个团队规划资源，以及如何确保他们可以共享有限的GPU资源，同时平衡GPU利用率的提高和良好的用户体验。

[29:58 - 29:59] 实际上这非常困难。

[29:59 - 30:02] 有时候这是一个权衡。

[30:02 - 30:09] 所以它真的取决于你如何定义你的系统，以及你对GPU利用率的关注程度。

[30:09 - 30:17] 所以你需要在那里找到正确的平衡，然后设计基础设施以确保它可以发生。

[30:18 - 30:19] 是的，谢谢。

[30:19 - 30:23] 然后这就是我们会议的内容，我们可以回答一些问题。

[30:23 - 30:27] 不幸的是，我认为我们已经没有时间了，但是感谢你们，wewei和auen。

[30:27 - 30:30] 我想你们会在后面逗留。

[30:30 - 30:33] 所以如果你有问题，请随时去找他们。

[30:33 - 30:34] 但是谢谢你。

[30:34 - 30:35] 每个人都来了。

[30:35 - 30:35] 谢谢。

[30:35 - 30:36] 是的。

